{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 3:\n",
      "Image - Min Value: 4 Max Value: 234\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 4 Name: deer\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBjZAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ff83860>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 3\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #print (x.shape)\n",
    "    #print (x)\n",
    "    #print (x / 255.0)\n",
    "    return x / 255.0\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    one_hot = np.array(np.zeros([len(x),10]))\n",
    "    #print (one_hot)\n",
    "    \n",
    "    #print (x.shape)\n",
    "    #print (x)\n",
    "    \n",
    "    index = 0\n",
    "    for item in x:\n",
    "        #print (item)\n",
    "        one_hot[index][item] = 1\n",
    "        index += 1\n",
    "    \n",
    "    #print (one_hot)\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=[None,image_shape[0],image_shape[1],image_shape[2]], name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=[None,n_classes], name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #print (x_tensor.shape, conv_num_outputs, conv_ksize, conv_strides)\n",
    "    \n",
    "    #filter_channels = int(x_tensor.shape[3]) #不转类型为什么会报错？\n",
    "    filter_channels = x_tensor.get_shape().as_list()[3]\n",
    "    filter_width = conv_ksize[0]\n",
    "    filter_height = conv_ksize[1]\n",
    "    \n",
    "    weight = tf.Variable(tf.truncated_normal([filter_width,filter_height,filter_channels,conv_num_outputs]))\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    conv_strides_array = [1, conv_strides[0], conv_strides[1], 1]\n",
    "    conv_padding = 'VALID'\n",
    "    conv = tf.nn.conv2d(x_tensor, weight, conv_strides_array, conv_padding)\n",
    "    conv = tf.nn.bias_add(conv, bias)\n",
    "    conv = tf.nn.relu(conv)\n",
    "    \n",
    "    pool_ksize_array = [1,pool_ksize[0],pool_ksize[1],1]\n",
    "    pool_strides_array = [1,pool_strides[0],pool_strides[1],1]\n",
    "    pool_padding = 'VALID'\n",
    "    pool = tf.nn.max_pool(conv, pool_ksize_array, pool_strides_array, pool_padding)\n",
    "    \n",
    "    return pool\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #print (x_tensor.shape)\n",
    "    size = x_tensor.get_shape().as_list()\n",
    "    flatten_tensor = tf.reshape(x_tensor, [-1, size[1] * size[2] * size[3]])\n",
    "    #print (flatten_tensor.shape)\n",
    "    \n",
    "    return flatten_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #print (x_tensor.shape, num_outputs)\n",
    "           \n",
    "    fully_conn_tensor = tf.layers.dense(x_tensor, num_outputs, activation=tf.nn.relu)\n",
    "    \n",
    "    #print (fully_conn_tensor.shape)\n",
    "    \n",
    "    return fully_conn_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 128) 40\n",
      "(?, 40)\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    print (x_tensor.shape, num_outputs)\n",
    "    \n",
    "    output_tensor = tf.layers.dense(x_tensor, units=num_outputs, activation=None)\n",
    "    \n",
    "    print (output_tensor.shape)\n",
    "    \n",
    "    return output_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv:\n",
      "3\n",
      "(?, 7, 7, 10)\n",
      "conv_layer:  (?, 7, 7, 10)\n",
      "flatten:\n",
      "flatten_layer:  (?, 490)\n",
      "fully_conn:\n",
      "fully_conn_layer:  (?, 1024)\n",
      "output:\n",
      "(?, 1024) 10\n",
      "(?, 10)\n",
      "output_layer:  (?, 10)\n",
      "conv:\n",
      "3\n",
      "(?, 7, 7, 10)\n",
      "conv_layer:  (?, 7, 7, 10)\n",
      "flatten:\n",
      "flatten_layer:  (?, 490)\n",
      "fully_conn:\n",
      "fully_conn_layer:  (?, 1024)\n",
      "output:\n",
      "(?, 1024) 10\n",
      "(?, 10)\n",
      "output_layer:  (?, 10)\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    print ('conv:')\n",
    "    \n",
    "    conv_num_outputs = 10\n",
    "    conv_ksize = (4,4)\n",
    "    conv_strides = (2,2)\n",
    "    pool_ksize = (2,2)\n",
    "    pool_strides = (2,2)\n",
    "    \n",
    "    conv_layer = conv2d_maxpool(x, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    print (conv_layer.shape)\n",
    "    \n",
    "#     conv_layer = conv2d_maxpool(conv_layer, 20, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "#     print (conv_layer.shape)\n",
    "    \n",
    "#     conv_layer = conv2d_maxpool(conv_layer, 40, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    print ('conv_layer: ', conv_layer.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    print ('flatten:')\n",
    "    flatten_layer = flatten(conv_layer)\n",
    "    print ('flatten_layer: ', flatten_layer.shape)\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    print ('fully_conn:')\n",
    "    fully_conn_layer = fully_conn(flatten_layer, 1024)\n",
    "#     fully_conn_layer = tf.nn.dropout(fully_conn_layer, keep_prob)\n",
    "#     fully_conn_layer = fully_conn(fully_conn_layer, 512)\n",
    "#     fully_conn_layer = fully_conn(fully_conn_layer, 256)\n",
    "    print ('fully_conn_layer: ', fully_conn_layer.shape)\n",
    "    \n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    print ('output:')\n",
    "    output_layer = output(fully_conn_layer, 10)\n",
    "    print ('output_layer: ', output_layer.shape)\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    return output_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #print (keep_probability, feature_batch.shape, label_batch.shape)\n",
    "    \n",
    "    session.run(optimizer, feed_dict={x:feature_batch, y:label_batch, keep_prob:keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #print('print_stats: ', valid_features.shape, valid_labels.shape)\n",
    "    #print('print_stats: ', feature_batch.shape, label_batch.shape, cost, accuracy)\n",
    "    \n",
    "    loss = session.run(cost, feed_dict = {x: feature_batch, y: label_batch, keep_prob: 1.0})\n",
    "    validation_accuracy = session.run(accuracy, feed_dict = {x: valid_features, y: valid_labels, keep_prob: 1.0})\n",
    "    print(\"Loss: \", loss, \", Validation accuracy: \", validation_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "keep_probability = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:  1.94691 , Validation accuracy:  0.418\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:  1.63585 , Validation accuracy:  0.4548\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:  1.46344 , Validation accuracy:  0.4746\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:  1.3322 , Validation accuracy:  0.48\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:  1.22634 , Validation accuracy:  0.4818\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:  1.10817 , Validation accuracy:  0.493\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:  0.983288 , Validation accuracy:  0.4884\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:  0.889342 , Validation accuracy:  0.4918\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:  0.790923 , Validation accuracy:  0.4888\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:  0.702331 , Validation accuracy:  0.4732\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:  0.514544 , Validation accuracy:  0.4882\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:  0.496162 , Validation accuracy:  0.4946\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:  0.339023 , Validation accuracy:  0.4968\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:  0.278089 , Validation accuracy:  0.4942\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:  0.217956 , Validation accuracy:  0.4634\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:  0.16486 , Validation accuracy:  0.477\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:  0.15938 , Validation accuracy:  0.5082\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:  0.119964 , Validation accuracy:  0.502\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:  0.0984565 , Validation accuracy:  0.4938\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:  0.063836 , Validation accuracy:  0.5038\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:  0.0375948 , Validation accuracy:  0.5156\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:  0.0256643 , Validation accuracy:  0.5186\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:  0.0258122 , Validation accuracy:  0.5086\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:  0.0313848 , Validation accuracy:  0.5058\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:  0.0194137 , Validation accuracy:  0.5088\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:  0.019071 , Validation accuracy:  0.5082\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:  0.0122643 , Validation accuracy:  0.5108\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:  0.0115478 , Validation accuracy:  0.5046\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:  0.00967861 , Validation accuracy:  0.5138\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:  0.00505641 , Validation accuracy:  0.5182\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:  0.00587609 , Validation accuracy:  0.5174\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:  0.00265115 , Validation accuracy:  0.5202\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:  0.00232149 , Validation accuracy:  0.5158\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:  0.00184221 , Validation accuracy:  0.5248\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:  0.0018251 , Validation accuracy:  0.5272\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:  0.00152698 , Validation accuracy:  0.527\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:  0.00129353 , Validation accuracy:  0.528\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:  0.00111548 , Validation accuracy:  0.5266\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:  0.000973171 , Validation accuracy:  0.5268\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:  0.000853559 , Validation accuracy:  0.5264\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:  0.000759418 , Validation accuracy:  0.5264\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:  0.000676546 , Validation accuracy:  0.5272\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:  0.000615351 , Validation accuracy:  0.5282\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:  0.000555844 , Validation accuracy:  0.5286\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:  0.000505956 , Validation accuracy:  0.5294\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:  0.000463162 , Validation accuracy:  0.5296\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:  0.000422593 , Validation accuracy:  0.5298\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:  0.000387424 , Validation accuracy:  0.5304\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:  0.000356693 , Validation accuracy:  0.5304\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:  0.000329546 , Validation accuracy:  0.53\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-0ebd1bbc35ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mbatch_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_preprocess_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mtrain_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_probability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {:>2}, CIFAR-10 Batch {}:  '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-208-b042e1d62552>\u001b[0m in \u001b[0;36mtrain_neural_network\u001b[0;34m(session, optimizer, keep_probability, feature_batch, label_batch)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#print (keep_probability, feature_batch.shape, label_batch.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfeature_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mkeep_probability\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnd/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnd/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnd/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/envs/dlnd/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnd/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:  1.98704 , Validation accuracy:  0.3872\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:  1.57023 , Validation accuracy:  0.438\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:  1.36386 , Validation accuracy:  0.4678\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:  1.29669 , Validation accuracy:  0.4908\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:  1.43832 , Validation accuracy:  0.4876\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:  1.51691 , Validation accuracy:  0.5116\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:  1.21981 , Validation accuracy:  0.5092\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:  1.11311 , Validation accuracy:  0.531\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:  0.975542 , Validation accuracy:  0.543\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:  1.17519 , Validation accuracy:  0.5492\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:  1.26126 , Validation accuracy:  0.5496\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:  0.963385 , Validation accuracy:  0.544\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:  0.897246 , Validation accuracy:  0.5552\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:  0.795605 , Validation accuracy:  0.5624\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:  0.947355 , Validation accuracy:  0.5676\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:  1.10757 , Validation accuracy:  0.5698\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:  0.795816 , Validation accuracy:  0.5598\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:  0.639253 , Validation accuracy:  0.5646\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:  0.650319 , Validation accuracy:  0.5782\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:  0.746997 , Validation accuracy:  0.5762\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:  0.926684 , Validation accuracy:  0.567\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:  0.703814 , Validation accuracy:  0.5654\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:  0.456042 , Validation accuracy:  0.5694\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:  0.500783 , Validation accuracy:  0.5858\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:  0.579715 , Validation accuracy:  0.5862\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:  0.739918 , Validation accuracy:  0.575\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:  0.57105 , Validation accuracy:  0.5688\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:  0.325157 , Validation accuracy:  0.5668\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:  0.385635 , Validation accuracy:  0.5886\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:  0.416207 , Validation accuracy:  0.585\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:  0.592116 , Validation accuracy:  0.5722\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:  0.470972 , Validation accuracy:  0.5584\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:  0.251368 , Validation accuracy:  0.5614\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:  0.298991 , Validation accuracy:  0.5868\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:  0.286041 , Validation accuracy:  0.573\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:  0.439265 , Validation accuracy:  0.5728\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:  0.338158 , Validation accuracy:  0.564\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:  0.188903 , Validation accuracy:  0.5584\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:  0.220766 , Validation accuracy:  0.5768\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:  0.189063 , Validation accuracy:  0.5692\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:  0.320839 , Validation accuracy:  0.5752\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:  0.221712 , Validation accuracy:  0.56\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:  0.130886 , Validation accuracy:  0.56\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:  0.147532 , Validation accuracy:  0.5754\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:  0.1562 , Validation accuracy:  0.5726\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:  0.294832 , Validation accuracy:  0.5742\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:  0.145161 , Validation accuracy:  0.5608\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:  0.110895 , Validation accuracy:  0.5594\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:  0.144816 , Validation accuracy:  0.57\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:  0.12294 , Validation accuracy:  0.5762\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:  0.188529 , Validation accuracy:  0.5714\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:  0.136941 , Validation accuracy:  0.55\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:  0.091257 , Validation accuracy:  0.563\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:  0.102385 , Validation accuracy:  0.5584\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:  0.0972398 , Validation accuracy:  0.5856\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:  0.135842 , Validation accuracy:  0.5742\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:  0.0747704 , Validation accuracy:  0.5456\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:  0.104189 , Validation accuracy:  0.5544\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:  0.112261 , Validation accuracy:  0.5638\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:  0.118591 , Validation accuracy:  0.5752\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:  0.114432 , Validation accuracy:  0.5696\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:  0.0896682 , Validation accuracy:  0.5558\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:  0.0760794 , Validation accuracy:  0.5606\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:  0.0821879 , Validation accuracy:  0.5642\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:  0.0707489 , Validation accuracy:  0.5738\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:  0.0783366 , Validation accuracy:  0.5668\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:  0.0578942 , Validation accuracy:  0.5542\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:  0.0306232 , Validation accuracy:  0.5524\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:  0.0636134 , Validation accuracy:  0.5552\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:  0.0621325 , Validation accuracy:  0.574\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:  0.051934 , Validation accuracy:  0.5716\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:  0.0589802 , Validation accuracy:  0.5766\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:  0.0464946 , Validation accuracy:  0.559\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:  0.047435 , Validation accuracy:  0.5614\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:  0.0411746 , Validation accuracy:  0.5668\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:  0.0457751 , Validation accuracy:  0.5794\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:  0.0515924 , Validation accuracy:  0.5674\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:  0.0392702 , Validation accuracy:  0.563\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:  0.0354665 , Validation accuracy:  0.5742\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:  0.0358787 , Validation accuracy:  0.5776\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:  0.0292003 , Validation accuracy:  0.567\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:  0.025581 , Validation accuracy:  0.5708\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:  0.00569051 , Validation accuracy:  0.571\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:  0.036102 , Validation accuracy:  0.5706\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:  0.0288298 , Validation accuracy:  0.5782\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:  0.0535865 , Validation accuracy:  0.5754\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:  0.0128418 , Validation accuracy:  0.5738\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:  0.015034 , Validation accuracy:  0.5746\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:  0.0314839 , Validation accuracy:  0.5672\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:  0.0208466 , Validation accuracy:  0.5656\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:  0.0421869 , Validation accuracy:  0.567\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:  0.0471824 , Validation accuracy:  0.5524\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:  0.0152111 , Validation accuracy:  0.568\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:  0.0229566 , Validation accuracy:  0.5664\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:  0.0278101 , Validation accuracy:  0.5598\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:  0.0308967 , Validation accuracy:  0.5686\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:  0.0322917 , Validation accuracy:  0.5456\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:  0.0107795 , Validation accuracy:  0.5688\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:  0.0216214 , Validation accuracy:  0.5684\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:  0.0160461 , Validation accuracy:  0.5694\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:  0.0215021 , Validation accuracy:  0.568\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:  0.0165778 , Validation accuracy:  0.5528\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:  0.019558 , Validation accuracy:  0.5772\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:  0.0130253 , Validation accuracy:  0.568\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:  0.0177072 , Validation accuracy:  0.5726\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:  0.0259055 , Validation accuracy:  0.5638\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:  0.00854021 , Validation accuracy:  0.5658\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:  0.0130794 , Validation accuracy:  0.5634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, CIFAR-10 Batch 4:  Loss:  0.0191201 , Validation accuracy:  0.5604\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:  0.0239825 , Validation accuracy:  0.5616\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:  0.0118944 , Validation accuracy:  0.5642\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:  0.0103849 , Validation accuracy:  0.5672\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:  0.00762451 , Validation accuracy:  0.5658\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:  0.0111799 , Validation accuracy:  0.573\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:  0.0183359 , Validation accuracy:  0.5696\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:  0.0292774 , Validation accuracy:  0.5674\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:  0.0133913 , Validation accuracy:  0.5712\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:  0.00720398 , Validation accuracy:  0.57\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:  0.0291349 , Validation accuracy:  0.5762\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:  0.0113475 , Validation accuracy:  0.5676\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:  0.0130301 , Validation accuracy:  0.5718\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:  0.00893224 , Validation accuracy:  0.5772\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:  0.00841438 , Validation accuracy:  0.5806\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:  0.0129361 , Validation accuracy:  0.56\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:  0.0123796 , Validation accuracy:  0.5806\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:  0.0152181 , Validation accuracy:  0.5694\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:  0.00928941 , Validation accuracy:  0.5854\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:  0.00625943 , Validation accuracy:  0.5834\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:  0.00990429 , Validation accuracy:  0.5664\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:  0.0078968 , Validation accuracy:  0.5714\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:  0.00726146 , Validation accuracy:  0.5722\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:  0.0079063 , Validation accuracy:  0.5792\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:  0.0088432 , Validation accuracy:  0.5802\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:  0.0223747 , Validation accuracy:  0.5668\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:  0.0078568 , Validation accuracy:  0.5662\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:  0.0124692 , Validation accuracy:  0.5856\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:  0.00530463 , Validation accuracy:  0.5828\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:  0.00358487 , Validation accuracy:  0.5852\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:  0.00498492 , Validation accuracy:  0.5768\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:  0.00427157 , Validation accuracy:  0.572\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:  0.0078148 , Validation accuracy:  0.5746\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:  0.0057236 , Validation accuracy:  0.5716\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:  0.00721376 , Validation accuracy:  0.5874\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:  0.0112759 , Validation accuracy:  0.5726\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:  0.00522186 , Validation accuracy:  0.577\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:  0.0112511 , Validation accuracy:  0.584\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:  0.00334443 , Validation accuracy:  0.5772\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:  0.00443378 , Validation accuracy:  0.58\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:  0.00775155 , Validation accuracy:  0.5818\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:  0.00625696 , Validation accuracy:  0.5754\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:  0.00257207 , Validation accuracy:  0.5828\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:  0.00492431 , Validation accuracy:  0.5788\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:  0.00701459 , Validation accuracy:  0.5844\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:  0.00990863 , Validation accuracy:  0.569\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:  0.00981131 , Validation accuracy:  0.5806\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:  0.00450399 , Validation accuracy:  0.5776\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:  0.00612819 , Validation accuracy:  0.5756\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:  0.00137719 , Validation accuracy:  0.574\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:  0.00631956 , Validation accuracy:  0.5704\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:  0.0120309 , Validation accuracy:  0.5766\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:  0.0085802 , Validation accuracy:  0.5736\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:  0.00260911 , Validation accuracy:  0.5758\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:  0.0101338 , Validation accuracy:  0.5822\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:  0.00473289 , Validation accuracy:  0.5698\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:  0.00644553 , Validation accuracy:  0.5844\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:  0.00839971 , Validation accuracy:  0.5848\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:  0.00641792 , Validation accuracy:  0.5832\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:  0.00645912 , Validation accuracy:  0.5792\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:  0.00284846 , Validation accuracy:  0.5714\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:  0.0038563 , Validation accuracy:  0.5758\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:  0.0109103 , Validation accuracy:  0.5794\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:  0.0059867 , Validation accuracy:  0.5682\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:  0.00210715 , Validation accuracy:  0.5786\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:  0.00305918 , Validation accuracy:  0.5792\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:  0.0029326 , Validation accuracy:  0.58\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:  0.0131662 , Validation accuracy:  0.5792\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:  0.00683656 , Validation accuracy:  0.5756\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:  0.00370151 , Validation accuracy:  0.5762\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:  0.00116968 , Validation accuracy:  0.5764\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:  0.0082602 , Validation accuracy:  0.5786\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:  0.00213982 , Validation accuracy:  0.5756\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:  0.00529918 , Validation accuracy:  0.587\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:  0.00509767 , Validation accuracy:  0.575\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:  0.00324636 , Validation accuracy:  0.576\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:  0.00662852 , Validation accuracy:  0.5778\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:  0.00599761 , Validation accuracy:  0.5796\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:  0.00659228 , Validation accuracy:  0.5736\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:  0.00213201 , Validation accuracy:  0.575\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:  0.00170326 , Validation accuracy:  0.5776\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:  0.00414506 , Validation accuracy:  0.5738\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:  0.00659815 , Validation accuracy:  0.578\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:  0.00769894 , Validation accuracy:  0.583\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:  0.00266435 , Validation accuracy:  0.5744\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:  0.00661846 , Validation accuracy:  0.5818\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:  0.00493924 , Validation accuracy:  0.5854\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:  0.00899099 , Validation accuracy:  0.5794\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:  0.00156531 , Validation accuracy:  0.5818\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:  0.00252234 , Validation accuracy:  0.577\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:  0.00578267 , Validation accuracy:  0.5776\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:  0.00390217 , Validation accuracy:  0.5744\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:  0.00575912 , Validation accuracy:  0.5836\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:  0.00431282 , Validation accuracy:  0.579\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:  0.000855634 , Validation accuracy:  0.575\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:  0.00466402 , Validation accuracy:  0.5792\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:  0.00507652 , Validation accuracy:  0.5814\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:  0.00282114 , Validation accuracy:  0.5776\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:  0.0012117 , Validation accuracy:  0.5714\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:  0.00534389 , Validation accuracy:  0.5822\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:  0.00103046 , Validation accuracy:  0.5802\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:  0.00523843 , Validation accuracy:  0.572\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:  0.00230363 , Validation accuracy:  0.5804\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:  0.00173072 , Validation accuracy:  0.5752\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:  0.00208156 , Validation accuracy:  0.5832\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:  0.000579401 , Validation accuracy:  0.5858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, CIFAR-10 Batch 5:  Loss:  0.00668888 , Validation accuracy:  0.5764\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:  0.00216308 , Validation accuracy:  0.59\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:  0.00423253 , Validation accuracy:  0.577\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:  0.00393844 , Validation accuracy:  0.5882\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:  0.00568477 , Validation accuracy:  0.5772\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:  0.00481318 , Validation accuracy:  0.575\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:  0.00190924 , Validation accuracy:  0.5836\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:  0.00116465 , Validation accuracy:  0.5792\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:  0.00797675 , Validation accuracy:  0.5782\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:  0.00171124 , Validation accuracy:  0.5768\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:  0.00553336 , Validation accuracy:  0.5862\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:  0.00542416 , Validation accuracy:  0.5808\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:  0.0010013 , Validation accuracy:  0.5788\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:  0.00457624 , Validation accuracy:  0.5856\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:  0.00196477 , Validation accuracy:  0.5852\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:  0.00309798 , Validation accuracy:  0.5754\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:  0.00593878 , Validation accuracy:  0.5848\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:  0.000542362 , Validation accuracy:  0.5708\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:  0.000155258 , Validation accuracy:  0.5788\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:  0.00384825 , Validation accuracy:  0.5828\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:  0.00403837 , Validation accuracy:  0.5736\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:  0.000979074 , Validation accuracy:  0.589\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:  0.00156097 , Validation accuracy:  0.5816\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:  0.00266787 , Validation accuracy:  0.5876\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:  0.00316392 , Validation accuracy:  0.5848\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:  0.000990506 , Validation accuracy:  0.5778\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:  0.00180301 , Validation accuracy:  0.5818\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:  0.005447 , Validation accuracy:  0.5816\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:  0.00107561 , Validation accuracy:  0.5884\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:  0.00345132 , Validation accuracy:  0.5784\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:  0.00246159 , Validation accuracy:  0.5824\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:  0.00203078 , Validation accuracy:  0.5856\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:  0.0013938 , Validation accuracy:  0.5796\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:  0.000457917 , Validation accuracy:  0.5734\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:  0.00232035 , Validation accuracy:  0.5748\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:  0.0101678 , Validation accuracy:  0.5822\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:  0.00101251 , Validation accuracy:  0.5848\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:  0.00187318 , Validation accuracy:  0.5794\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:  0.000411921 , Validation accuracy:  0.5804\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:  0.0021419 , Validation accuracy:  0.5754\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:  0.00472053 , Validation accuracy:  0.5718\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:  0.000431779 , Validation accuracy:  0.5788\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:  0.00429442 , Validation accuracy:  0.586\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:  0.00233687 , Validation accuracy:  0.5804\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:  0.00278103 , Validation accuracy:  0.5744\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:  0.00767036 , Validation accuracy:  0.571\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:  0.00149781 , Validation accuracy:  0.5766\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:  0.00148821 , Validation accuracy:  0.5758\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:  0.00390291 , Validation accuracy:  0.5878\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:  0.00070491 , Validation accuracy:  0.574\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:  0.00263166 , Validation accuracy:  0.5786\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:  0.00233788 , Validation accuracy:  0.5756\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:  0.00466725 , Validation accuracy:  0.58\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:  0.00121812 , Validation accuracy:  0.5766\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:  0.000438 , Validation accuracy:  0.5782\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:  0.0027184 , Validation accuracy:  0.5822\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:  0.00191056 , Validation accuracy:  0.5822\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:  0.00596244 , Validation accuracy:  0.5692\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:  0.00143968 , Validation accuracy:  0.5738\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:  0.000962891 , Validation accuracy:  0.5762\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:  0.000516444 , Validation accuracy:  0.5818\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:  0.0043823 , Validation accuracy:  0.5766\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:  0.00123535 , Validation accuracy:  0.5712\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:  0.00209391 , Validation accuracy:  0.5724\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:  0.00209437 , Validation accuracy:  0.5714\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:  0.000545905 , Validation accuracy:  0.5734\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:  0.00456991 , Validation accuracy:  0.5742\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:  0.00173782 , Validation accuracy:  0.5798\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:  0.00132334 , Validation accuracy:  0.5814\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:  0.00170716 , Validation accuracy:  0.5822\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:  0.00195688 , Validation accuracy:  0.5758\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:  0.00465158 , Validation accuracy:  0.5742\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:  0.00201168 , Validation accuracy:  0.5778\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:  0.000591872 , Validation accuracy:  0.5742\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:  0.000931193 , Validation accuracy:  0.5696\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:  0.0012278 , Validation accuracy:  0.576\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:  0.000611944 , Validation accuracy:  0.5832\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:  0.0030111 , Validation accuracy:  0.5724\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:  0.000562929 , Validation accuracy:  0.5822\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:  0.00153014 , Validation accuracy:  0.5818\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:  0.000448694 , Validation accuracy:  0.5748\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:  0.00229532 , Validation accuracy:  0.577\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:  0.000951975 , Validation accuracy:  0.5792\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:  0.00104784 , Validation accuracy:  0.5858\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:  0.000434891 , Validation accuracy:  0.578\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:  0.00294026 , Validation accuracy:  0.586\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:  0.00821507 , Validation accuracy:  0.5762\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:  0.000495096 , Validation accuracy:  0.5852\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:  0.00479174 , Validation accuracy:  0.5836\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:  0.00170964 , Validation accuracy:  0.5768\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:  0.000598209 , Validation accuracy:  0.584\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:  0.00095719 , Validation accuracy:  0.5828\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:  0.0016483 , Validation accuracy:  0.58\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:  0.000903845 , Validation accuracy:  0.5874\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:  0.00139034 , Validation accuracy:  0.583\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:  0.00031224 , Validation accuracy:  0.5752\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:  0.00356214 , Validation accuracy:  0.5824\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:  0.00305125 , Validation accuracy:  0.5876\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:  0.000992809 , Validation accuracy:  0.5838\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:  0.00209905 , Validation accuracy:  0.5714\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:  0.00160672 , Validation accuracy:  0.5754\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:  0.00462384 , Validation accuracy:  0.5766\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:  0.0040418 , Validation accuracy:  0.5732\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:  0.000279653 , Validation accuracy:  0.5778\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:  0.00143174 , Validation accuracy:  0.573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64, CIFAR-10 Batch 5:  Loss:  0.00197859 , Validation accuracy:  0.5752\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:  0.00138947 , Validation accuracy:  0.5796\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:  0.00181325 , Validation accuracy:  0.5714\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:  0.000219403 , Validation accuracy:  0.5858\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:  0.00425614 , Validation accuracy:  0.5756\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss:  0.00121486 , Validation accuracy:  0.5688\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:  0.00218492 , Validation accuracy:  0.5718\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:  0.00109082 , Validation accuracy:  0.5838\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:  0.00277034 , Validation accuracy:  0.5838\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:  0.000388993 , Validation accuracy:  0.5742\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:  0.000516722 , Validation accuracy:  0.5778\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:  0.00186039 , Validation accuracy:  0.573\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:  0.0010172 , Validation accuracy:  0.58\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:  0.000364717 , Validation accuracy:  0.5808\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:  0.000663908 , Validation accuracy:  0.5842\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:  0.00342783 , Validation accuracy:  0.5722\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:  0.00541233 , Validation accuracy:  0.5724\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:  0.00166639 , Validation accuracy:  0.5834\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:  0.000337921 , Validation accuracy:  0.5844\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:  0.00481767 , Validation accuracy:  0.5826\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:  0.00283123 , Validation accuracy:  0.573\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:  0.01812 , Validation accuracy:  0.5802\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:  0.00189922 , Validation accuracy:  0.5842\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:  0.000942632 , Validation accuracy:  0.5892\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:  0.00187962 , Validation accuracy:  0.5748\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:  0.00122865 , Validation accuracy:  0.5836\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:  0.00196743 , Validation accuracy:  0.578\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:  0.000726123 , Validation accuracy:  0.577\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:  0.00165326 , Validation accuracy:  0.5784\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:  0.00176315 , Validation accuracy:  0.5734\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:  0.0015439 , Validation accuracy:  0.5726\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:  0.000858656 , Validation accuracy:  0.5882\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:  9.2893e-05 , Validation accuracy:  0.5858\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:  0.000222536 , Validation accuracy:  0.5904\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:  0.000503106 , Validation accuracy:  0.5794\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:  0.00034124 , Validation accuracy:  0.5832\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:  0.000994475 , Validation accuracy:  0.5778\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:  0.00121328 , Validation accuracy:  0.5806\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:  0.00420105 , Validation accuracy:  0.5836\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:  0.000960108 , Validation accuracy:  0.584\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:  0.00103507 , Validation accuracy:  0.586\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:  0.000873574 , Validation accuracy:  0.5876\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:  8.67609e-05 , Validation accuracy:  0.589\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:  0.00108638 , Validation accuracy:  0.5916\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:  0.00270019 , Validation accuracy:  0.5876\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:  0.00065237 , Validation accuracy:  0.5852\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:  0.000532415 , Validation accuracy:  0.585\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:  0.000368952 , Validation accuracy:  0.587\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:  0.000682613 , Validation accuracy:  0.5874\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:  0.00340016 , Validation accuracy:  0.583\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:  0.00133898 , Validation accuracy:  0.5828\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:  0.00158212 , Validation accuracy:  0.5824\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:  0.00215987 , Validation accuracy:  0.5804\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:  0.000396184 , Validation accuracy:  0.5814\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:  0.000173575 , Validation accuracy:  0.5808\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:  0.000830177 , Validation accuracy:  0.5792\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:  0.00177605 , Validation accuracy:  0.5786\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:  0.00180152 , Validation accuracy:  0.5796\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:  0.000889708 , Validation accuracy:  0.5834\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:  0.00034907 , Validation accuracy:  0.5786\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:  0.000284652 , Validation accuracy:  0.582\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:  0.000702909 , Validation accuracy:  0.5838\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:  0.00264342 , Validation accuracy:  0.5732\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:  0.00299986 , Validation accuracy:  0.5752\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:  0.0010966 , Validation accuracy:  0.578\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:  0.00423591 , Validation accuracy:  0.572\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:  0.000431118 , Validation accuracy:  0.577\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:  0.00033766 , Validation accuracy:  0.5884\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:  0.000396626 , Validation accuracy:  0.5828\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:  0.000836303 , Validation accuracy:  0.5774\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:  0.000943463 , Validation accuracy:  0.5828\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:  0.00213359 , Validation accuracy:  0.5884\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:  0.00101377 , Validation accuracy:  0.5766\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:  0.00151158 , Validation accuracy:  0.5746\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:  0.000311486 , Validation accuracy:  0.5806\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:  0.00179003 , Validation accuracy:  0.578\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:  4.50312e-05 , Validation accuracy:  0.571\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:  0.000137201 , Validation accuracy:  0.5834\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:  0.000237343 , Validation accuracy:  0.5786\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:  0.000245567 , Validation accuracy:  0.564\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:  0.000950593 , Validation accuracy:  0.5756\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:  0.00172001 , Validation accuracy:  0.5726\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:  6.34539e-05 , Validation accuracy:  0.5778\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:  4.04397e-05 , Validation accuracy:  0.588\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:  5.88699e-05 , Validation accuracy:  0.58\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:  8.05387e-05 , Validation accuracy:  0.5846\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:  4.47057e-05 , Validation accuracy:  0.5724\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:  0.000163743 , Validation accuracy:  0.581\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:  0.000193177 , Validation accuracy:  0.5728\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:  0.000297953 , Validation accuracy:  0.5784\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:  0.00107755 , Validation accuracy:  0.5728\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:  0.000964181 , Validation accuracy:  0.577\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:  0.00123544 , Validation accuracy:  0.5808\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:  0.00100095 , Validation accuracy:  0.5788\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:  0.00096992 , Validation accuracy:  0.5798\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:  0.00159627 , Validation accuracy:  0.578\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:  0.0001603 , Validation accuracy:  0.5808\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:  0.00259828 , Validation accuracy:  0.579\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:  0.000420678 , Validation accuracy:  0.5826\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:  0.000592453 , Validation accuracy:  0.5684\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:  0.000835462 , Validation accuracy:  0.58\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:  0.000490791 , Validation accuracy:  0.5778\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:  0.00127701 , Validation accuracy:  0.5834\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:  0.000628978 , Validation accuracy:  0.5808\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:  0.00310021 , Validation accuracy:  0.561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85, CIFAR-10 Batch 5:  Loss:  0.000363845 , Validation accuracy:  0.5634\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:  0.00210722 , Validation accuracy:  0.5746\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:  0.00124735 , Validation accuracy:  0.5732\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:  0.0009387 , Validation accuracy:  0.5814\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss:  0.00143352 , Validation accuracy:  0.575\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:  0.000437721 , Validation accuracy:  0.5656\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:  0.000586561 , Validation accuracy:  0.5824\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:  0.000989714 , Validation accuracy:  0.5752\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss:  0.000155807 , Validation accuracy:  0.5812\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:  0.00118535 , Validation accuracy:  0.5746\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:  0.000163893 , Validation accuracy:  0.5828\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:  0.00133647 , Validation accuracy:  0.5824\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:  0.000352046 , Validation accuracy:  0.5764\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:  0.000522131 , Validation accuracy:  0.5828\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:  0.00366848 , Validation accuracy:  0.5746\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:  6.0942e-05 , Validation accuracy:  0.5792\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:  0.00161777 , Validation accuracy:  0.5838\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:  0.0010279 , Validation accuracy:  0.5756\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:  0.00212438 , Validation accuracy:  0.5812\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:  0.00269616 , Validation accuracy:  0.5756\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:  0.00068981 , Validation accuracy:  0.5774\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:  0.000137043 , Validation accuracy:  0.5682\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:  0.000776267 , Validation accuracy:  0.576\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:  0.00115098 , Validation accuracy:  0.5828\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:  3.24009e-05 , Validation accuracy:  0.5704\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:  0.000543953 , Validation accuracy:  0.5764\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:  9.55561e-05 , Validation accuracy:  0.58\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:  0.000211692 , Validation accuracy:  0.5792\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:  0.00035279 , Validation accuracy:  0.5798\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:  0.000804438 , Validation accuracy:  0.573\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:  0.000104673 , Validation accuracy:  0.574\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:  0.000290481 , Validation accuracy:  0.5738\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:  0.00293078 , Validation accuracy:  0.5688\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:  2.24707e-06 , Validation accuracy:  0.5812\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:  0.00149531 , Validation accuracy:  0.579\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:  4.08112e-05 , Validation accuracy:  0.5708\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:  0.000325224 , Validation accuracy:  0.5816\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:  0.000271765 , Validation accuracy:  0.5844\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:  0.00062546 , Validation accuracy:  0.5878\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:  0.000370082 , Validation accuracy:  0.5814\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:  8.35044e-05 , Validation accuracy:  0.5832\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:  0.000340664 , Validation accuracy:  0.5764\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:  0.000156705 , Validation accuracy:  0.5922\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:  0.000323895 , Validation accuracy:  0.5832\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:  0.00085507 , Validation accuracy:  0.5772\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:  0.000625763 , Validation accuracy:  0.58\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:  0.000231927 , Validation accuracy:  0.5864\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:  0.00105358 , Validation accuracy:  0.5832\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:  0.000834556 , Validation accuracy:  0.586\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:  0.000331776 , Validation accuracy:  0.5856\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:  0.00362377 , Validation accuracy:  0.5756\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:  0.000328964 , Validation accuracy:  0.5804\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:  0.00252452 , Validation accuracy:  0.5814\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:  8.26061e-05 , Validation accuracy:  0.58\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:  0.000531172 , Validation accuracy:  0.5796\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:  0.000303521 , Validation accuracy:  0.5762\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:  0.00176801 , Validation accuracy:  0.5796\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:  6.20171e-06 , Validation accuracy:  0.5842\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:  7.30491e-05 , Validation accuracy:  0.5864\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:  8.95104e-05 , Validation accuracy:  0.5816\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:  0.000753983 , Validation accuracy:  0.5802\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:  0.00260504 , Validation accuracy:  0.5766\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:  0.0011751 , Validation accuracy:  0.5832\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:  7.18587e-05 , Validation accuracy:  0.5758\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:  2.64159e-05 , Validation accuracy:  0.586\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:  0.000966237 , Validation accuracy:  0.5758\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:  0.000309082 , Validation accuracy:  0.5738\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:  0.000823624 , Validation accuracy:  0.5778\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:  0.000503187 , Validation accuracy:  0.5854\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:  0.000529748 , Validation accuracy:  0.5744\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:  0.00118731 , Validation accuracy:  0.5766\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:  0.00039624 , Validation accuracy:  0.5778\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:  6.33822e-05 , Validation accuracy:  0.5778\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:  2.26087e-05 , Validation accuracy:  0.5782\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:  0.000556935 , Validation accuracy:  0.574\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:  0.000770889 , Validation accuracy:  0.5764\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.5822054140127388\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsQAAAJ/CAYAAAB/WMU1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3XeYZEd19/Hv6Z48m5Mi0iIh0IJI\nEkiArESwCSYYEwzYRshgcsY2hhcjGQdewCQR/BKEAAMSBgM2IDISQiAEEggrIRRWYSVt3p2dHPq8\nf5zqvnfu9sz07KSd6d/nefrp6Xvr1q3u6VB9+lSVuTsiIiIiIs2qtNANEBERERFZSOoQi4iIiEhT\nU4dYRERERJqaOsQiIiIi0tTUIRYRERGRpqYOsYiIiIg0NXWIRURERKSpqUMsIiIiIk1NHWIRERER\naWrqEIuIiIhIU1OHWERERESamjrEIiIiItLU1CEWERERkaamDrGIiIiINDV1iBeYmR1tZs82s1ea\n2d+b2VvN7LVm9lwze5SZLVvoNk7EzEpm9kwzu8jMbjGzHjPz3OXrC91GkYONmW0svE7OnY2yBysz\nO7NwH85e6DaJiBS1LHQDmpGZrQFeCbwMOHqK4hUzuwG4HPgW8EN3H5zjJk4p3YevAGctdFtk/pnZ\nhcCLpyg2CuwBdgDXEM/hL7n73rltnYiIyPQoQjzPzOyPgRuAf2LqzjDE/+gEogP9TeA5c9e6afkc\n0+gMK0rUlFqAdcDxwAuBjwNbzOxcM9OX8UWk8Nq9cKHbIyIy2/ShNI/M7HnAF4FyYVcP8L/AfcAQ\nsBo4CtjEQfilxcweAzwtt+kO4DzgV8C+3Pb++WyXLArdwDuB083sKe4+tNANEhERUYd4npjZsURU\nNd8Zvg54O/Btdx+tc8wy4AzgucCfACvmoamNeHbh9jPd/doFaYkcLP6GSKHJawEOAf4AeBXxJa/q\nLCJifM68tE5ERGQS6hDPn38G2nO3fwA8w90HJjrA3XuJvOFvmdlrgZcSUeSFdlLu783qDAuww903\n19l+C3CFmX0Y+ALxxa7qbDP7sLv/Zj4auBilx9QWuh0z4e6Xssjvg4gsfQfdz/FLkZl1As/IbRoB\nXjxZZ7jI3fe5+wfc/Qez3sDp25D7+54Fa4UsGum5/iLg5txmA16xMC0SERHJqEM8P04EOnO3f+bu\ni7kjmZ8KbmTBWiGLSuoUf6Cw+QkL0RYREZE8pUzMj0MLt7fM58nNbAVwGnAEsJYY+LYV+IW733kg\nVc5i82aFmR1DpHIcCbQBm4Efu/u2KY47kshxvR9xv+5Nx909g7YcATwEOAZYlTbvAu4Eft7k0479\nsHD7WDMru/vYdCoxsxOABwOHEQP1Nrv7Fxs4rh14HDHDywZgjHgt/NbdfzudNkxQ/3HAycDhwCBw\nN3CVu8/ra75Oux4IPAJYTzwn+4nn+nXADe5eWcDmTcnM7gc8hshJX068nu4BLnf3PbN8rmOIIMb9\niDEfW4Er3P22GdT5IOLxP5QIKIwCvcBdwO+Bm9zdZ9h0EZkJd9dlji/AnwGeu1wyT+d9FHAJMFw4\nf/7yW2JKLJuknjMnOX6iy6Xp2M0HemyhDRfmy+S2nwH8GKjUqWcY+BiwrE59Dwa+PcFxFeCrwBEN\nPs6l1I6PA7dOcd/GiPzxsxqs+7OF4z8xjf//vxaO/eZk/+dpPrcuLNR9doPHddZ5TDbUKZd/3lya\n2/4SohNXrGPPFOc9AfhPoG+S/81dwBuA1gN4PE4FfjFBvaPEWICTUtmNhf3nTlJvw2XrHLsK+Efi\ni9hkz8ntwAXAo6f4Hzd0aeD9o6HnSjr2ecBvJjnfCPB94DHTqPPS3PGbc9tPIb6w1XtPcOBK4LHT\nOE8r8GYij36qx20P8Z7zpNl4feqiiy7Tvyx4A5rhAjy+8Oa3D1g1h+cz4D2TvLHXu1wKrJ6gvuIH\nWkP1pWM3H+ixhTaM+3BO217X4H38JblOMTFLRn8Dx20Gjmrg8T7nAO6jA/8GlKeouxu4sXDcnzXQ\npicVHpu7gbWz+By7sNCmsxs8rqPO47C+Trn88+ZSYkDqlyd5LOt2iIkvK+8lvog0+n+5lga/DKVz\nvK3B5+EwkUe9sbD93Enqbrhs4bg/AXZP8/n4myn+xw1dGnj/mPK5Qsyo84NpnvuDQKmBui/NHbM5\nbXstkwcO8v/D5zVwjvXEYjTTffy+PluvUV100WV6F6VMzI+riQ/k6pRry4DPmdkLPWaSmG2fBP6q\nsG2YiHDcQ0SOHkUsmlB1BvATMzvd3XfPQZtmVZrT+UPpphNRpFuJLwOPAI7NFX8UcD7wEjM7C7iY\nLF3opnQZJuZ9fmjuuKOJCO1UC5AUc/EHgOuJn6R7iKjoUcDDiHSOqjcREa63TlSxu/eZ2fOJ6GNH\n2vwJM/uVu99S7xgzOxT4PFlqyxjwQnffOcX9mA9HFm470XGbygeJ6Qerx/yarNN8DHD/4gFmVib+\n139a2NVPvCbvJV6TxwIPJ3u8Hgb8zMxOdvetkzXKzN5AzCCTN0b8v+4ift5/JJHa0Up0MouvzVmV\n2vR+9k9tuo/4RWgH0EX8Lx7K+NlvFpyZLQcuI17HebuBq9L1YUQKRb7tryfe0/58mud7EfDh3Kbr\niKjuEPHcOInssWwFLjSzX7v77yeoz4D/Iv7veVuJ+eZ3EF+gVqb6H4DSF0UW3kL3yJvlQvxcXYwG\n3EMsUvBQZu+n7BcXzlEhOhOrCuVaiA/mvYXyX6pTZwcRqape7s6Vv7Kwr3o5NB17ZLpdTBt5ywTH\n1Y4ttOHCwvHV6Ne3gGPrlH8e0THNPw6PTY+5Az8DHlHnuDOBnYVzPXWKx7w6Hd6/pnPUjVIRX0T+\njvE/21eAUxr4v76i0KZfAW11ypWIn5DzZd8xB8/n4v/j7AaP++vCcbdMUG5zrsy+3N+fB46sU35j\nnW3/XDjXViLlot7jdiz7v0a/PcV9eSj7RxW/WHz+pv/J84BtqcyuwjHnTnKOjY2WTeX/iP2j4ZcR\nedP7vccQHcqnEz/XX13Yt47sNZmv7ytM/Nqt9384czrPFeAzhfI9wMsppLIQHcp/Y//o/MunqP/S\nXNlesveJrwEPqFN+E/GrQf4cF09S/9MKZX9PDB6t+x5P/Ar0TOAi4D9n+7Wqiy66NHZZ8AY0y4WI\nQA0W3ijzl51E5+4dxM/d3QdwjmXs/zPpG6c45hT2z6ucNI+NCfI7pzhmWh+KdY6/sM5j9gUm+YmU\nWO66Xif6B0D7JMf9caMffqn8oZPVV6f8YwvPhUnrzx13caFdH6pT5u2FMj+a7DGawfO5+P+Y8v9J\nfLEqpn/UzYmmfqrNu6fRvlMY3zH8HXW+aBWOKbF/zvZTJin/40LZj05R/0PYvzM8ax1iIuq7tVD+\nI43+/4FDJtmXr/PCaT5XGn7tEwNc82X7gVOnqP81hWN6mSD9K5W/tM7/4CNMPo7iEMa/tw5NdA5i\nLEG13Ahw/2k8Vh3TeWx10UWX2bto2rV54rF4xV8QHaF61gBPJQbBfA/YbWaXm9nL0ywRjXgx2awG\nAN9x9+I0V8V2/QL4h8Lm1zd4voV0DxEJmmx0/KeJCHhVdXT9X/gkSwa7+zeJDlTVmZM1xN3vm6y+\nOuV/Dnw0t+lZafaDqbyMSAupep2ZPbN6w8z+gFhCu2o78KIpHqN5YWYdRHT3+MKu/9dgFb8hOvuN\neitZKsso8Cx3n3RRm/Q4vZzxs8C8oV5ZM3sw458XNwNvnKL+64G/nbTVM/Myxs8R/mPgtY3+/32K\n9JB5UnzvOc/dr5jsAHf/CBHdr+pmemkp1xGBA5/kHFuJjm5VG5GyUU9+RcbfuPvtjTbE3Sf6fBCR\nOaYO8Txy9/8kfrr8aQPFW4loyb8Dt5nZq1Ju2mReVLj9zgab9mGi81T1VDNb0+CxC+UTPkX+tbsP\nA8UP04vc/d4G6v9R7u8NKS93Nn0j93cb++dL7sfde4jUk+Hc5s+Y2VHp//Ulsjx1B/6ywfs6G9aZ\n2cbC5QFm9jgz+1vgBuA5hWO+4O5XN1j/B7zBqdnStHf5hXC+6O43NnJs6pB8IrfpLDPrqlO0mKf6\nnvR8m8oFRMrRXHhZ4faknbyDjZl1A8/KbdpNpHs14v8Ubk8nj/gD7t7IfOrfLtx+eAPHrJ9GO0Rk\nAalDPM/c/dfufhpwOhHBnHSe3GQtEVG8yMza6hVIEcYTc5tuc/erGmzTCDElVa06Jo5+HCy+12C5\nWwu3v9/gccUBa9P+YLOw3MwOL3YW2X/AUzFyWpe7/4rIQ65aTXSEP8v4AWvvdffvTLfNM/Be4PbC\n5ffEF5L/y/6D3q5g/w7cZL45dZGaMxn/3vbVaRwL8JPc363Ao+uUeWzu7+o0fVNK0dqvTLM9UzKz\n9URKRtUvffEtqf5oxg8u+1qjv7yk+3pDbtND0+C8RjT6OrmpcHui94T8r0tHm9mrG6xfRBaQRrYu\nEHe/HLgcaj+/Po6YDeHRRLSw3peV5xEjlOu9wZ7A+BHXv5hmk64EXpW7fRL7R0QOJsUPp4n0FG7/\nrm6pqY+bMm0lzWrwRGI2hEcTndy6X2DqWN1gOdz9g2Z2JjEQB+K5k3cl00svmE8DxOwg/9BgVA7g\nTnffNY1znFq4vTt9CWlUuXD7GGJgWl7+y+fvfXqLQ/xyGmUbdUrh9uVzcI65dlLh9oG8hz04/V0i\n3kenehx6vPFVQ4sL6kz0nnAR49NnPmJmzyIGC17ii2AWH5FmpA7xQcDdbyCiG58CMLNVxE+HbySm\ngMp7lZldUOen5mK0ou6UQJModhQP9p/6Gl3tbXSWjmudrLCZPZbIh33oZOUm0WieeNVLiLzaowrb\n9wAvcPdi+xfCGPF47ySmSbucSF+YTucWxqfzNKI4tdtP6pZq3Lj0ofRrTP7/VfwVYip1p8uboWJK\nT0MpIgeZhXgPa3jVSHcfKWSt1X1PcPerzOxjjA8wPDFdKmb2v0Ta3E+IQcmN/EooInNMKRMHIXff\n4+4XEhGOf6xT5LV1tq0q3C5GOKdS/GBoOGK5EGYwUGzWB5iZ2ZOJAUwH2hmGab4WU5TpX+rserO7\nb55BOw7US9zdCpcWd1/r7g909+e7+0cOoDMMMWvAdMx2/vuywu3ia2Omr7XZsLZwe1aXM54nC/Ee\nNlcDTl9D/ErTX9heInKPX03MGnOvmf3YzJ7TwBgREZlD6hAfxDy8k3jjzHtiI4dP83R6Mz4AaTDb\nfzA+XWUz8C7gKcCDiA/6jnxnkToLSUzzvGuJKfqK/tzMmv11PWk0/wBM9do4GF9ri2Yw3SQOxse1\nIem9+1+IdJu/A37O/r86QXwGn0mM4bjMzA6bt0aKyDhKmVgczgeen7t9hJl1uvtAblsxIrRymuco\n/mSvPLfGvIrx0bmLgBc3MONAowN+9pMiSZ8Fjqiz+yxixH29XxaaRT4KPQp0znIKSfG1MdPX2mwo\nRt6L0dbFYMm9h6Xp2t4DvMfMlgEnA6cRr9NTGf8ZfBrwnbRCYsPTOIrI7Gj2SNJiUW+0ePHnwGKe\n5QOmeY4HTlGf1Pe03N97gZc2OP3WTKZxe2PhvFcxfraSfzCz02ZQ/2KXn0+3hRlG44tSZyX/c/6x\nE5WdwHRfm40ozrG8aQ7OMdeW9HuYu/e6+4/c/Tx3P5NYfvr/EANNqx4GnLMQ7RNpduoQLw718tyK\n+XXXMX5+2uKo86kUp1lrdH7YRi2Fn3DryX9o/9Td+xo87oCmtTOzRwHvzm3aTcxq8Zdkj3EZ+GJK\nq2hGVxZuP2EOznFN7u/j0kDYRtWbxm2mrmT8a2wxfiEqvufM5D2sQgw6PWi5+w53/2f2n37w6QvR\nHpFmpw7x4vCgwu3e4qIUKWqV/0A51syK0xjVZWYtRKeqVh3Tn/JoKsWfABudjuxgl/9Zt6FBQCnl\n4QXTPVFasfBixufInuPud7r7d4m5gKuOJKZ5akY/KNw+ew7O8fPc3yXgTxs5KOV3P3fKgtPk7tuB\n63ObTjazmQzyLMq/fufqtftLxufZ/slE864Xpfuan4f5OnffN5uNm0MXM34F040L1A6RpqYO8Tww\ns0PM7JAZVFH8Ce3SCcp9sXC7uCTzRF7D+CVfL3H3nQ0e26jiCPDZXvltoeTzHos/2U7kLziwn7Q/\nQQzSqTrf3b+eu/12xkdHn25mi2EZ7lnl7rcAP8xtOsXMiqs4ztQXCrf/1swaGcx3DvVzv2fDJwq3\n3z+LMxfkX79z8tpNv67kV3BcQ/051+t5V+H2f8xKo+ZBym/Pz0bRSMqViMwydYjnxyZi+eV3m9mG\nKUvnmNmfAq8sbC7OOlH1WcZ/cD3DzF41Qdlq/Y9m/w+TD0+njQ26DcgvxPD4OTjHQvjf3N8nmdkZ\nkxU2s5OJQZLTYmZ/zfiBlb8G/iZfJn2wvoDxnfT3mFl+EYlmcW7h9ifN7EnTqcDMDjOzp9bb5+7X\nM36xjgcCH5iivgcTA6zmyqcZnz/9ROCDjXaKp/jSnp/j99FpgNhcKL73vCu9R03IzF5JtkgNQB/x\nWCwIM3tlWjmw0fJPYfxUgY0uHiQis0gd4vnTRUy/c7eZfc3M/nSyN00z22RmnwC+zPiVs65h/0gw\nAOknwjcVNp9vZu81s3Ejts2sxcxeQixlnP9w+3L6+X1WpZSO/FLSZ5jZp8zsCWZ2XGFp48UUPS4u\nw/tVM3tGsZCZdZrZG4nI5QpixcGGmNkJwAdzm3qB59cbiZ7mIM7nJLYBF09jGdslwd1/yvh5mjuJ\nEfwfM7PjJjrOzFaZ2fPM7GJi+ry/nOQ0r2X8l7xXm9kXis9fMyuZ2XOJX3ZWM0dzBLt7P9He/JiD\n1wE/TAvH7MfM2s3sj83sK0y+MmV+cZNlwLfM7E/S+1RxWfKZ3IefAJ/PbeoGvm9mf1WMwJvZCjN7\nD/CRQjV/c4DzXc+WvwPuTM+FZ0302kvvwX9JLL2et2ii2yJLiaZdm3+txCp0zwIws1uAO4kOUoX4\nwHwwcL86x94NPHeyRSnc/QIzOx14cdpUAt4CvNbMfg7cS0zJ9GhgXeHwG9k/Gj2bzmf8srp/lS5F\nlxFzcy4GFxCzPlQ7WWuBb5jZHcSXl0HiJ+ZTiC9FEKPKX0nMPTopM+sifhHozG1+hbtPuIqXu3/F\nzP4deEXa9ADg48CfN3iflop3ECv5Ve93iXjcX5n+PzcQgxJbidfEcUwjf9Pd/9fM/g54f27zC4Hn\nm9mVwF1E5/EkYkYBiBzZNzJH+d3u/j0zewvwb2Tz8p4F/MzM7gV+S6wc2EnkmT+MbA7terPZVH0K\neDPQkW6fni71zDRN4zXE4hXVVTpXpvP/XzO7ivhCcSjw2Fx7qi5y94/P8PyzoYN4LrwQcDO7Gbid\nbCq4w4BHsv/Ucl939/+Zt1aKSI06xPNjF9HhLXZAITorjUwv9APgZQ2uQvaSdM43kH04tTN5J/On\nwDPnMrLi7heb2SlEh2BJcPehFBH+EVmnB+DodCnqJQZV3dTgKc4nviBVfcbdi/mr9byR+PJRHVj1\nIjP7obs3zUC79MXxL8zsWuCfGL94ykT/n6JJ57J19w+kLy3vInutlRn/xa9qlPgCONOlpCeV2rSF\n6ETmo5OHMf45Op06N5vZ2URHvnOK4jPi7j0p9ei/iM581VpisZuJfJSIiB9sjBgYXRwcXXQxWSBD\nROaZUibmgbv/lohoPJ6IJv0KGGvg0EHiQ+Hp7v6kRpfkTaskvYmYhuh71F8hqep64k349Pn4mTG1\n6xTiw+uXRLRqUQ8icfebgBOJnzoneqx7gc8BD3P37zRSr5m9gPEDKm+i/rLd9do0SOQc5wfrnG9m\nxzdy/FLi7u8jBiN+kP3n663nd8QXkce6+5S/mKSps05nfEpQXoV4HZ7q7p9rqNEz5O5fJuZffh/j\n84rr2UoMyJu0M+buFxPjIc4j0j/uZfwcurPG3fcQ0+W9kIhqT2SMSEM61d1fM4Ml3WfTM4nH6Eqm\nfm+rEO1/mrv/mRbkEFk45r5Up4c9uKWo0gPTZQNZJKeHiO5eD9wwGytspfzh04nR7WuIztlW4BeN\ndrKlMWnu39OJn947iMd5C3B5yvGUBZYGtz2M+MVmFfHFcw9wK3C9u2+b5PCp6j6O+CJ6WKp3C3CV\nu98103bPoE1GpCA8BFhPpHH0prZdD9zoB/kHgZkdRTyuhxDvlbuAe4jX1YKvSDcRM+sATiB+BTyU\neOxHiMHPtwDXLHC+s4gk6hCLiIiISFNTyoSIiIiINDV1iEVERESkqalDLCIiIiJNTR1iEREREWlq\n6hCLiIiISFNTh1hEREREmpo6xCIiIiLS1NQhFhEREZGmpg6xiIiIiDQ1dYhFREREpKmpQywiIiIi\nTU0dYhERERFpauoQi4iIiEhTU4dYRERERJqaOsQiIiIi0tTUIRYRERGRpqYOsYiIiIg0NXWIRURE\nRKSpqUMsIiIiIk1NHWIRERERaWrqEIuIiIhIU1OHWERERESamjrEIiIiItLU1CEWERERkabWstAN\nkPrM7GxgI/B1d//NwrZGREREZOlSh/jgdTZwBrAZUIdYREREZI4oZUJEREREmpo6xCIiIiLS1NQh\nPgBmtsnM/t3MbjazPjPbY2b/a2YfNrOTcuXazOxpZvZJM7vWzHaY2aCZ3WFmX8iXzR1ztpk5kS4B\n8Bkz89xl8zzdTREREZGmYO6+0G1YVMzstcAHgHLa1Ed8sehMty9z9zNT2T8G/id3eH8q25FujwLn\nuPvnc/U/H/gQsAZoBXqAgVwdd7n7o2fxLomIiIg0NUWIp8HMngt8mOgMfwV4sLsvA7qBw4E/B67O\nHdILfAZ4ArDO3bvdvRM4GvggMajxE2Z2VPUAd7/Y3Q8FfpY2vd7dD81d1BkWERERmUWKEDfIzFqB\n24AjgS+5+wtnoc5PA+cA57r7eYV9lxJpEy9x9wtnei4RERERqU8R4sY9gegMjwF/M0t1VtMpTp2l\n+kRERERkmjQPceMek66vdfctjR5kZmuAVwNPAR4ErCTLP646fFZaKCIiIiLTpg5x4w5J13c2eoCZ\nPRj4Ue5YgH3EIDkH2oDVRA6yiIiIiCwApUw0zg7gmM8QneFrgCcDy919hbsfkgbOPXcGdYuIiIjI\nLFCEuHH3peujGymcZo44mcg5fsYEaRaH1NkmIiIiIvNIEeLGXZmuH2ZmRzRQ/sh0vX2SnOMnTnJ8\nJV0reiwiIiIyh9QhbtwPgS3EgLj3NlB+b7o+xMw2FHea2UOByaZu60nXq6bTSBERERGZHnWIG+Tu\nI8Cb080XmNmXzez46n4zO8zMXmZmH06bbgTuJiK8F5vZA1K5VjN7NvB9YuGOiVyfrp9tZitn876I\niIiISEYLc0yTmb2JiBBXv0z0ElHjeks3/wmxol217D6gnZhd4k7g7cDngTvcfWPhPMcD16ayo8A2\nYAS4293/YA7umoiIiEhTUoR4mtz9/cAjiRkkNgOtwCDwW+BDwBtzZb8GPJ6IBu9LZe8A3pfquHuS\n89wEPAn4DpF+cSgxoO/IiY4RERERkelThFhEREREmpoixCIiIiLS1NQhFhEREZGmpg6xiIiIiDQ1\ndYhFREREpKmpQywiIiIiTU0dYhERERFpauoQi4iIiEhTU4dYRERERJqaOsQiIiIi0tRaFroBIiJL\nkZndDqwglngXEZHp2wj0uPv95/pES7ZD/LFLfucA2+7eVtt27PH3A+D6q34KwPEnPKi270EPPQmA\n3t4BAPp6+2v79uyOvzs72gHwsd7avr599wJw6X9dFGVas4d07VEnANC9fAMAhx9xeG3fytVrAdi3\nc0dtW3t7a5RfE/sOP2xFbd8h67sAaDWLNu3J2nDPll0A7LjjLgBGRwZr+1q7lgPQtX4lAFvuvKu2\n7667tgDwrr97qSEis21FZ2fnmk2bNq1Z6IaIiCxGN954IwMDA/NyriXbIS6Xo3O5bMXK2javRIe2\npTWuR/p7avva2yJ7pGV5PCStlmWTlEvdqfwQAHffdU9t38jIzrgejE7oUE/WkW5fFfWvWXUoAKXK\nWFZn6oL27N5Z29bZXgZgw2GHANCROsgAvT3xhBjui+sd27K2b787OrZ7d0bnvKO7O7vPfZ5OWAGg\nMjpS2zc0mLVVRGbd5k2bNq25+uqrF7odIiKL0kknncQ111yzeT7OpRxiEWl6ZnapmflCt0NERBbG\nko0Qi4gstOu27GXjW7+10M0QEVkQm9/9tIVuQsOWbId4356UUuBZmsLY8DAAO+6LvOJl7VlAqL8n\n0iF6dm0HoLMrS1eo5u0OD0Tebu+uLO93y5bbABgcilSENcs6a/vWrV8d5+mIuvbt3Frbt2JV5Ad3\nr1hW27Z9y50AtNxyMwADvetr++6549ZoQ1+0Ybg/y6np37017Ytc4s7OLGWi1BJpGKvudxwAe/uG\navt2bb0XERERkWanlAkRWVTM7GQzu9jMtpjZkJnda2bfM7Pn5cqcbWZfNbPbzGzAzHrM7Aoz+/NC\nXRtTqsQZ6bbnLpfO7z0TEZGFsmQjxG2MAjA8nEVSh3oigloZ7ANg78622r5tWyJauvXumIVh/SFr\na/vcIsK78567Adh93521fcN9EYnuaI+BepTLtX1WiQj0zlR+z+7ttX2l1lSulP0Ltm+PNuzbHRHs\n227IIthb74t97a3Rlv5d92V3dqQ/nTrqbC9nx7WW4zvP3oGIjm/ryWag2HrfFkQWEzN7GfBxYAz4\nb+D3wAbgUcCrgC+noh8HbgB+AtwLrAWeCnzezB7k7u9I5fYA5wFnA0env6s2z+FdERGRg8iS7RCL\nyNJiZg8GPgb0AKe5+/WF/Ufmbp7g7rcW9rcBlwBvNbN/d/ct7r4HONfMzgSOdvdzD6BdE00jcfx0\n6xIRkYWxZDvE3emeuY3Wtu3dFhHRtlJETbdvyaZP+901vwKgMjaaymb5tT09u+N6R2y78/Zbavss\n1WUeubl7d2UR6eXLI6LMSMpP3ptNsdbSEpHe1o4s53jr3ZGPXKpENLd/797sDpXjDrWkCPHwvj3Z\nrmpEuBT7SmQR4q62iFxX7twc93lvNn/xwMgwIovIK4n3rHcVO8MA7n537u9b6+wfNrOPAo8HngB8\nbg7bKiIii8iS7RCLyJLzmHRwaetzAAAgAElEQVR9yVQFzewo4O+Iju9RQGehyBGz1Sh3P2mCNlwN\nnDhb5xERkbmjDrGILBar0vWkye9mdgxwFbAauBz4HrCXyDveCLwYaJ+zVoqIyKKzZDvEO++NgWz7\nUroDwEDPPgBGR2KKtKH+vtq+31/7cwDaO2MatIHcKm47790cf1TTKXqyVIZaykQaxDc2mqVoDG3/\nHQCHr406796dtWXMYyq3cjmb6GP7ljsA8LGYKs5zdY2NxUpz1WnUSLcBPJ27lKaHI7cQc19nLPlc\nLsXGvbuztg9pGQJZXKp5QkcAN01S7k3EILqXuPuF+R1m9gKiQywiIlKzZDvEIrLkXEnMJvEUJu8Q\nPyBdf7XOvjMmOGYMwMzK7rnJy2fohCNWcvUimpheRKRZLdkO8a9/+j0ABgf21ba1lyK6unxVTKnW\nuyeL2PbtisUtupdFNHdoLPtMHOqNqKqPxLbhXOS2GnnFIupcyg1Ue8ghEf19yCMiXfEX191R27d1\nR5y7lIsQD6WotI9G9Nc9iwJX0me0p6nccrtoSf/F1jRQr5RbgXYoLUZiaVBe32A26K/iuVCyyMHv\n48ArgHeY2Xfd/Yb8TjM7Mg2s25w2nQn8T27/HwEvnaDu6ojXo4DbZ7HNIiKyCCzZDrGILC3ufoOZ\nvQr4d+DXZvYNYh7itUTkeB9wFjE120uA/zSzrxI5xycATybmKX5+nep/CDwX+C8z+zYwANzh7p+f\n23slIiIHA3WIRWTRcPdPmtl1wFuICPCzgB3Ab4FPpTK/NbOzgH8iFuNoAa4Fnk3kIdfrEH+KWJjj\nz4C/TcdcBqhDLCLSBJZsh3jvXZFi2N7ZWtu27pDVAKy0HQDs6ttR21dd0e7+nTE7U89QlpNQ/S11\niMq4sgBtFg9hxWLfiauyleoef+L9ASitXh7XY1k6Rc+eSOUot2X/gtGx6sC8qMssS2mwlAZRTW+s\n5FI6xobjuPY053B7OauzNBopGZVSavtYlk5RKmnlbll83P3nwJ9OUeZnxHzD9eyXK5Tyht+WLiIi\n0mTUIxIRERGRprZkI8T39cSUamO5xd627onIbjUou7c3m1pteCQNZCtHhLetnEWWly1fCUA5RW73\nDQzW9rW0dwBwTHdEaZ/5qMNr+444fAMAd+6uTveWRYiHRuPvtlJu+rQUZa6UYoBePkI8OBjbWlvi\nO0xbW0dt3+hwmlJtoC/dv7bavs6O+LucotslzyLE+fpFREREmpUixCIiIiLS1JZshHjd6sinrYxl\nU6RVfCRdR5R0+bLs7ldSoHZkKKZD81IWPW1riRzgcinKr+jO9i0josVn3T/ykx943MbavmoEtr09\nvnesWpl9/1hXibpacznEHV3VbXHccBZQpnffUNSZireUswjx0GDcx/6BqH80t2hHS1qPqzKWIsyt\nWY5ze+uS/feLiIiINEwRYhERERFpauoQi4iIiEhTW7K/mT/4QesBaM+tBJcWeaOcMgqslKUPUIqd\nI5WYzqycO65kUa6jNfIPhvqywXhrdkeKxcMOSwPvOrpq+7wl0hpWroi6H3/yMbV9t9zXA8DAaNYG\na41ylgbXUclSM8aIfYMjkfrguenTvFJNsYjUiaHcSnpDwylNpFo+lwpSttz9FxEREWlSihCLiIiI\nSFNbshHiPUMx2K0tN4isGjjtSoPJunLz81djqkMpOlsiG5jWPpKiqzGujb57ttX2PSgtttFVWRcb\nssAtEOfubInznXrcmtqedau6Abhz50ht296RaPO+oTjR4HAW6a2OoVs2EnW25qK7lqaKG6ou1mHZ\ncft6o30txDRyreXsuOHc4h4iIiIizUoRYhERERFpaks2QlxurS5nnPX521oiIlwqR2R0LPd1oJKW\nRG5JU5aN7Rmq7etLKzUPDKRo7tYsQlzpjNDtcFoGuW00i7r2b98CgFvUtbY7O+Gp69YCcPxgFqW+\nZnMsJX3N7b1xXDmLUpdTm9vS1G/5SG/fQGprqspykd9Wj3Ijo9XId6b6eIiIiIg0M0WIRURERKSp\nqUMsIiIiIk1tyaZMkFaJG8jGl1H2SBuwUkpF8CwlYWhvpB0Mp1SJscFs36jH94aB/sidaOnP0in2\nlmMUXceaGCRX7swe0h13bQWgPc3EtubIVbV9rRbH3W9VW3aejbHa3R3bI3Vi856B2r6W0Sg/mtpu\n5dzUamlI4Nhw7Bval6VMjI5FykSaAY6h3Kg/Gxk3AlBERESkKSlCLCKzwsw2mpmb2YUL3RYREZHp\nWLIR4lUroq8/OJJFc4dHIoLaXo6o7Mj2wdq+3m19UT4NUCt3ZgtsjFUiAlsZievR1o7avhv3xXGP\n3BYLdBx/TLb4xk6LhTyWdXdGna3Lsgam6PTYSBbpPbw7znnsYYcCcOfOO2r7ymnQnrVG9Le9PYtg\ntwxFpLc3BZRL7dlpLE0LV0mR7LGRbDDerj3Z/RcRERFpVku2QywistCu27KXjW/9VkNlN7/7aXPc\nGhERmYhSJkRERESkqS3ZCPFoKVIRhoaztABLq7v1bo15fnfdvqe2b2ggrWzXHYPjVrRlaRFDPXsB\n8LR63Vhba23fXSlN4bKrbgFg/f0Oq+3r7IxUiQpRZ/9Ad21f2YZTQ7OUjs5y/L26K81pXMoGvQ2P\npBSQdH+GK1nKxNhw1NuVVsRrtX21fbv3Vo+LQYYjY321fXuHslXyRGaTmW0E3g08EVgGXAec6+7f\nLJRrB94IvBB4ALFo5LXA+e7+5Tp13g58FvgX4F3AWcA64PHufqmZHQO8FXg8cAQwAGwBrgDe7u47\nC3W+APhr4BFAZ6r/C8B73X0IERFpCku2QywiC+Zo4CrgNuDzwBrg+cA3zOyJ7v5jADNrA74LnAHc\nBHwU6AKeA1xsZo9w97fVqf9Y4BfAzUTntRPoMbPDgF8CK4BvA18FOoD7A38BfASodYjN7NPAOcDd\nwH8Be4DHEB3tJ5jZk9w9N09NfWZ29QS7jp/qWBEROTgs2Q7x3VsikjpWya1Ul2YjG703wrrDY7kD\nWiPq294V0daRSvY5WKlEwTSTG4PD2XRoY+Wo/zfbI+q88Tc31fYdf8wRUXVXmq7N19T2DaQpz4b7\ndte2rV4V25al6PRYLnq8Nw3229kfUd1Kru1Hr4hRdKtWxsbd/dl9rk7TNpLq2t6XRZ1HyD8AIrPm\nTCIafF51g5l9EfgO8DfAj9PmNxOd4UuAZ1Q7n2Z2HtGh/nsz+6a7/6xQ/x8A/1rsLJvZa4nO9xvc\n/UOFfd1AJXf7bKIz/DXgRe4+kNt3LvBO4NXAuHpERGRpUg6xiMy2O4B/ym9w9+8CdwIn5zafAzjw\npnwk1t23EVFagJfWqX8rcF6d7VUDxQ3u3pfv9AKvJ9IzzilsJ517J/CiSc6Rr/ukehci6i0iIovA\nko0QD41FMGiwP8uTbeuJv0uDERntXLY829ceU7GVy5FnPNCf5dqOjMZndcnjuLFc/q6nvF3viinT\nfnnHrtq+XT3xObt+eUSfjz9uXda+0ZTPvCc7z+DK2Lb2kMhDfujhWT7yFXdsAaAylqaAs2z6tB0D\nkY+8eW/6XLfse05Xa0SPd6c52QY9ixAPDQ4jMgd+4+71fn64C3gsgJktJ3KGt7h7vY7jj9L1I+vs\nu3aC/N7/JnKLP2pmf0SkY1wB3OCePfHNrAt4OLADeINVf/oZbwjYVG+HiIgsPUu2QywiC2bPBNtH\nyX6VWpmu752gbHX7qjr77qt3gLvfYWYnA+cCTwaenXbdZWbvc/cPp9urAQPWE6kRIiLS5JQyISIL\nYW+6PnSC/YcVyuVNuOa4u9/o7s8H1gKPImacKAEfMrO/KtT5a3e3yS7TukciIrJoLdkI8cq0Olzn\nSJYeuK+vH4CWlEbQ0p4t6dbSGg9FJaVDDA1nqRaDQ/HrrKeBaS0t2cPWlgbjVTMY9g5ln9W3bIvp\nz1rKMVDv5lu21vatWRUD51rb2mrbRrsihcMHewA4ZW1nbd+O/ljlbk9vWlEv91k94FHeWqKuodzq\nfJXRdJ9TSsgyctO1TTl+XmRuuPs+M7sVOMbMjnP33xeKnJWurznA+keBq4GrzexnwE+AZwGfdvde\nM7seeIiZrXH3XZPVNRMnHLGSq7XghojIQU8RYhFZKBcQqQvvNcuS4s1sHfCOXJmGmNnJZnZInV3V\nbf25be8H2oALzGy/tAwzW21mJzZ6bhERWdyWbIS4lKYUG92bG1TXHpHajuUrACi3ZAtsVMcAGdWB\nZlkktTroxlL5cmv2sJXTtGuVNGYnP+Cua1lEZTs7xw9sA1i1IkVsV2RR4D1pgN1oe9R1+LosevyQ\n1XHuX98T5xsezj7bD1sZ+7pXxuf6PT3ZQL2Otmj7cFqEY7AvCwuPVbL6RRbA+4CnAM8ErjWzbxPz\nED8X2AC8x91/Oo36Xgi82swuA24BdhNzFj+dGCT3wWpBd7/AzE4CXgXcambVWTDWEPMWnw58BnjF\njO6hiIgsCku2QywiBzd3HzazJwFvIjqzryVbqe4N7v6laVb5JaAdeBxwIrFgxxbgIuDf3P26wvlf\nbWaXEJ3eJxID+HYRHeP3Av9xgHdNREQWmSXbIe4ajMhoL9lyyd1rIke3NS29PDaamxmqElHZkTSF\nWSm38sWyNKVaKeULV3L7LCXiVmd1Ms8ixC0pytybIsPLcwHZ0XQ+z0WUR/pjcY9tffHr8frDsuWj\ny21Rvnc4yvf1Z9HmrWMRNV5J5A4P56ZTK43GcXv2xbbR3Exr+3ZrYQ6ZPe6+mUiBmGj/mXW2DRJT\npf3LLNT/C2IFu4alpaS/OWVBERFZ0pRDLCIiIiJNTR1iEREREWlqSzZlYqQn8hNaO7KBc5TSALjq\nfGOVbMCdp1yCoeHqlGXZL7NtaRBdKaVaDOemVquuf1VJq9nlFpBjYCB2bhuJulffb2VtXzlN/daW\nK9/aGef53W0xXdvRD85SJvpKUXDf3rRqXu4/t613MM6XpoUbGcnyIlYsj3MODMa+UiUbVDcylHts\nRERERJqUIsQiIiIi0tSWbIR4XwqEeikbOOYjsbFiEbkt5SPEI/F3dXDcQG7AXWsK1FoaADc2mouy\nDqaFL9LUbKVSNo1aS0tsGxiIAXBDA1mdnS1R14p12RSot2yLNvT1pmh1+7Lavtu2xKIeLSnK3dWZ\nRY/7d8U0az3D0a7hkex7TpulyLBF3UN9WRs6cguTiIiIiDQrRYhFREREpKmpQywiIiIiTW3JpkwM\nD0WaQqmcGziW5g+ujEVKQkspGxxXHULXluYa7u3PBqYNj0S59pRqMVIbeAdD6TwVi4dyuDObbLij\nM+YvrqYtDPfsqu3ztJhcS8f9a9s2HHEYAMdteiAAezvX1fbdcvvvAFiV2tfTm1uFNjW+q+2QdLO3\ntmvHvjhRh0V6RN9wbp7kVn0fEhEREVGPSERERESa2pKNEFdGYxDZWC6aWw2lllKkd3Q4t6JbGhRH\nOaY36+zIBpy1pG1jaWo2H8utVFeddi1FnYcHsshtR2sMitt46Jo4vndfVmdrRJLb27OI8omP2QjA\nPX3xb7nq9z21fd4a7RsZG0jHZ9PCtZciEr1ubVzv2Jrdr/60at1ImjKutTP7DlQZyqLFIiIiIs1K\nEWIRERERaWpLNkJcSlHdwYG+bFtLREnLbRGVHRnMIqljg7G4RVtnd7WC2r6Kx3Rmo8NRV5ksslpq\niXLVbxalShaRLqeFMjYeE3nCXbamtm/l6hUA3NmbfSe558pbAfjFrXsB2DGStWH79p0A7BuKtgyO\n5NqwPCLPO/rS9G5kUeeurvi7s5wW7bDsuJFyNn2ciIiISLNShFhEREREmpo6xCKyqJjZZjPbvNDt\nEBGRpWPJpkykBecot2TpA5U07dpwGmg3lhtT5sQBYyOROmGt2XHV1eva0ipxlkuZ6O6IcivSdbtn\naQhruqP86q5IfVh36Oravu0pHeLC715X27a7J87d2RXpFH3eVds3OhZ1VTzSPvoHsqnVRgdjAGFn\nKbW5lKWJWDm2LU+r5g2NZIPx+gaW7L9fREREpGGKEIuIiIhIU1uyIcLRNEWalXJ9/kpEb8dG4trK\n2d2vTqQ2MJimTRvJBsd1t3cA0NoSdXW0ZscduiwisEeujmjummXZvtXL4++2rojqltq7a/t+eu09\nAPz6lm21bV2dUW5DivRWylkkenQ4osA9aaGN1lIWwR7Yk9qaBsm1d+YW32iPbQMpcN3etjy7X2OD\niIiIiDQ7RYhF5KBj4TVmdr2ZDZrZFjP7iJmtnKB8u5m91cx+a2b9ZtZjZpeb2fMmqf/1ZnZDsX7l\nKIuINJ8lGyEeG4mIajX/F8iWbh5N4dJSlk9bSYt2uMV3BM8lGA8PRgR2fVr4Yllrthz0qo4ovyHW\n4ODwDR3ZvjURjW1dGUswX7U5i8hedsO9AAwOZznHHWlauL19cb7W1mxauLa2+Fd1pIU8RnKLioyO\nxv0arcS0aytXZ5Foa4/70dsX51m3ImtDe0kLc8hB64PA64B7gU8AI8AzgVOANqD2AjCzNuC7wBnA\nTcBHgS7gOcDFZvYId39bof6PAq8E7kn1DwPPAE4GWtP5RESkSSzZDrGILE5m9jiiM3wrcLK770rb\n3w78GDgMuCN3yJuJzvAlwDPcY2SrmZ0HXAX8vZl9091/lrafRnSGbwZOcfc9afvbgB8Ahxfqn6q9\nV0+w6/hG6xARkYWllAkROdi8JF3/c7UzDODug8Df1yl/DuDAm6qd4VR+G/CudPOlufIvztW/J1d+\neIL6RURkiVuyEWJP6RHkUybS1GoVj1SBsmWpDy1tkQ7RZvF5Whnqr+0bSikTlaF4uA5fn6UkbFjd\nGduOiKnS1m/I7UvTrP3vPbHy3Bd+nAWd7tgdg+NGx7JfZkeJY4dT+kY1VSMaFvdnw6o4X/9g9q9r\nTwMHK0ORMrF3b24FvraY3q11NMqPtGar3/Xn0i5EDiInpuvL6uy7HKh1es1sOfAAYIu731Sn/I/S\n9SNz26p//7RO+Svz9TfC3U+qtz1Fjk+st09ERA4uihCLyMGmOnBua3GHu48BO+uUvXeCuqrbVx1g\n/SIi0gSWbIS4OuisNTcAbiwNpquMRbS1XMqipS3tEXntbo9IcbktG3BX6oqBbJ3p68P67uy4hx5/\nOAAb7rcBgGVrs8/d5R0Rie7ffDsAd2zfUds3XKmuHJLVNToa5ZelXWNjWRv27d0XxVdGI/Ijftat\niDqWjcXIvpu3ZwtzDKfIcHd36373q4Xs3CIHkb3p+hDgtvwOMysDa4EthbKHTlDXYYVyAD3TqF9E\nRJqAIsQicrC5Jl2fUWffaeS+yLv7PmLw3RFmdlyd8mcV6gT4dbr+gzrlH8MSDhSIiEh96hCLyMHm\nwnT9djNbU91oZh3Av9YpfwFgwHtThLdafh3wjlyZqs/l6l+ZK98G/MuMWy8iIovOko2EjAzHgLSW\nlixlotwSd9fSQLvKaDaozFNqRXtaTW7V8uy4ta2RoHDosvisPXxdZ23f6jTnb/eqGFRXzq1i562R\nnlBqrc5NnM372z8QA+AGR7JtI4OR0lGuRLs6W7M5jffti0F+LR3Rhr2D2XeZUnekdJTL0eZDjsgG\n9u3rifSQMY/7MDKWDTLs7NA8xHLwcfcrzOx84LXAdWb2FbJ5iHezf77w+4CnpP3Xmtm3iXmInwts\nAN7j7j/N1X+ZmX0C+GvgejP7aqr/6URqxT3kX6wiIrLkLdkOsYgsaq8n5gl+NfByYqDb14C3Adfm\nC7r7sJk9CXgT8EKiIz2ayr3B3b9Up/5XEot4vBx4RaH+u4k0jJnaeOONN3LSSXUnoRARkSnceOON\nABvn41w2biU3EZEmlvKQbwYucvcXzLCuIaBMoQMvssCqC8bUm6ZQZCHVe25uBHrc/f5zfXJFiEWk\n6ZjZocA2d6/ktnURS0ZDRItn6jqYeJ5ikYVQXVlRz0s52Cz0c1MdYhFpRm8AXmBmlxI5yYcCTwCO\nJJaA/s+Fa5qIiMw3dYhFpBl9H3g48IfAGiLn+Gbgw8AHXblkIiJNRR1iEWk67v5D4IcL3Q4RETk4\naB5iEREREWlq6hCLiIiISFPTtGsiIiIi0tQUIRYRERGRpqYOsYiIiIg0NXWIRURERKSpqUMsIiIi\nIk1NHWIRERERaWrqEIuIiIhIU1OHWERERESamjrEIiIiItLU1CEWEWmAmR1pZheY2T1mNmRmm83s\ng2a2epr1rEnHbU713JPqPXKu2i5L22w8N83sUjPzSS4dc3kfZOkxs+eY2flmdrmZ9aTn0X8cYF2z\n8v47mZbZqkhEZKkys2OBnwEbgG8ANwEnA68Hnmxmp7r7zgbqWZvqeSDwI+Ai4HjgJcDTzOyx7n7b\n3NwLWYpm67mZc94E20dn1FBpRv8HeDjQC9xNvNdN2xw8x+tSh1hEZGofI96MX+fu51c3mtn7gTcC\n/wy8ooF6/oXoDH/A3d+Uq+d1wIfSeZ48i+2WpW+2npsAuPu5s91AaVpvJDrCtwBnAD8+wHpm9Tk+\nEXP3mdYhIrJkmdkxwK3AZuBYd6/k9i0H7gUM2ODufZPU0w1sByrAYe6+L7evlM6xMZ1DUWKZ0mw9\nN1P5S4Ez3N3mrMHStMzsTKJD/AV3//NpHDdrz/GpKIdYRGRyj0/X38u/GQOkTu0VQBfwmCnqeSzQ\nCVyR7wyneirA99LNs2bcYmkWs/XcrDGz55vZW83sTWb2FDNrn73mikzbrD/HJ6IOsYjI5B6Urm+e\nYP/v0/UD56kekaq5eE5dBPwr8G/At4E7zew5B9Y8kRmbt/dNdYhFRCa3Ml3vnWB/dfuqeapHpGo2\nn1PfAJ4OHEn8knE80TFeBVxsZk+ZQTtFDtS8vW9qUJ2IyMxUcy5nOiBjtuoRqWr4OeXuHyhs+h3w\nNjO7BzifGBB6yew2T2TGZu19UxFiEZHJVSMQKyfYv6JQbq7rEamaj+fUp4gp1x6RBjGJzKd5e99U\nh1hEZHK/S9cT5agdl64nynGb7XpEqub8OeXug0B1EGj3gdYjcoDm7X1THWIRkclV5878wzQ9Wk2K\nmJ0KDABXTlHPlancqcVIW6r3DwvnE5nKbD03J2RmDwJWE53iHQdaj8gBmvPneJU6xCIik3D3W4kp\n0TYCry7sPo+Imn0uPwemmR1vZuNWZXL3XuDzqfy5hXpek+r/ruYglkbN1nPTzI4xsyOK9ZvZOuAz\n6eZF7q7V6mROmFlrem4em99+IM/xA26DFuYQEZlcnaVDbwROIeYMvhl4XH7pUDNzgOIiB3WWbr4K\n2AQ8E9iW6rl1ru+PLB2z8dw0s7OJXOHLiEUQdgFHAU8lcjd/BTzJ3ffM/T2SpcLMngU8K908FPgj\n4Dbg8rRth7u/JZXdCNwO3OHuGwv1TOs5fsDtVYdYRGRqZnY/4B+JpZXXEiskfR04z913FcrW7RCn\nfWuAdxIfFIcBO4nR+//g7nfP5X2QpWmmz00zeyjwZuAk4HBioNI+4Hrgy8D/c/fhub8nspSY2bnE\ne91Eap3fyTrEaX/Dz/EDbq86xCIiIiLSzJRDLCIiIiJNTR1iEREREWlq6hBPwMw2m5mb2ZnTPO7c\ndNyFc9MyMLMz0zk2z9U5RERERJqFOsQiIiIi0tTUIZ59O4iVVe5d6IaIiIiIyNRaFroBS427fwT4\nyEK3Q0REREQaowixiIiIiDQ1dYgbYGZHmdmnzOwuMxs0s9vN7H1mtrJO2QkH1aXtbmYbzWyTmX02\n1TliZl8vlF2ZznF7OuddZvZJMztyDu+qiIiISNNRh3hqDyCWrfwrYBXgxJrabwZ+ZWaHHUCdp6U6\n/5JYFnPc+vCpzl+lc2xM51wFvBS4Bhi31reIiIiIHDh1iKf2PmAvcJq7Lwe6iSVXdxCd5c8eQJ0f\nA34JPNTdVwBdROe36rOp7h3AM4HudO7TgR7g3w7sroiIiIhIkTrEU2sHnuLuPwVw94q7fwN4Xtr/\nJDP7g2nWuS3VeV2q0939VgAzOw14Uir3PHf/b3evpHKXE+t4d8zoHomIiIhIjTrEU/uyu99S3Oju\nPwZ+lm4+Z5p1fsTdBybYV63rynSO4nlvAS6e5vlEREREZALqEE/t0kn2XZauT5xmnT+fZF+1rssm\nKTPZPhERERGZBnWIp7algX3rp1nn9kn2Veu6p4HzioiIiMgMqUM8M3aAx40t0HlFREREpEAd4qkd\nPsm+6pRrk0V8p6taVyPnFREREZEZUod4amc0sO+aWTxfta7TGziviIiIiMyQOsRTe76ZHVPcaGan\nA6emm/85i+er1vXYdI7ieY8Bnj+L5xMRERFpauoQT20YuMTMHgdgZiUzezrwlbT/++5+xWydLM13\n/P108ytm9sdmVkrnPhX4DjA0W+cTERERaXbqEE/tLcBq4Aoz2wf0Av9NzAZxC/DiOTjni1Pd64H/\nAXrTuX9KLOH85kmOFREREZFpUId4arcAjwIuIJZwLgObieWTH+Xu9872CVOdjwbeD9yRzrkX+DQx\nT/Gts31OERERkWZl7r7QbRARERERWTCKEIuIiIhIU1OHWERERESamjrEIiIiItLU1CEWERERkaam\nDrGIiIiINDV1iEVERESkqalDLCIiIiJNTR1iEREREWlq6hCLiIiISFNrWegGiIgsRWZ2O7CCWOpd\nRESmbyPQ4+73n+sTLdkO8fEP2+QAI0ODua1jALSU425XcstWV//y0VEARiujtX2t5TIAlm6Xyq21\nfeW2+LutozPqrGRnq1SG4zgbTcdnAfmyRZ0DA/21bS2tUUdbuq6QX1Y7ji2V0rk9O9HIWGrzyAgA\nw0N9tX1DA71xPsqp7VmN7vF4bL59myEis21FZ2fnmk2bNq1Z6IaIiCxGN954IwMDA/NyriXbIe5e\nsQ4YnxMyWkkd4pboFZZbst7hyEh0XkeGBtK+7KGx1F0spQ50S0tbti91rkvpulzKjhsZjTpHh4b2\na9/IUA8AnV2ra9vKqRPrv5gAACAASURBVOM9mNrQ0tqea0Pck6HBOK4ynD1BhkeiQ9zS3jGuHoCu\nVH8p3VfPfQmojGWdfhGZdZs3bdq05uqrr17odoiILEonnXQS11xzzeb5OJdyiEXkoGJmm81s80K3\nQ0REmoc6xCIiIiLS1JZsysTwcKQpeEqTAKikHNuRlEg7Nja233HlcnxHGB3qz21NqRKtkb87lks7\nGOmPfN1yKY6zXLpCuTVSKyqj0RZryVIg2jpXADDYn+X7Dg9GGsTIWEq1GM5SLUrp2HJrFwDtnStr\n+7pSPnJlzNP5Rmr7RkfSuS32jYxk+6rlRWRuXLdlLxvf+q2FboaIyILY/O6nLXQTGqYIsYiIiIg0\ntaUbIe7fB4CRm0AhRUmrXwOsnO1raUsD7coxMK1k2XcFSxHizu7lAIzl9rWlaGx1Nouurixy29Yx\nvq7+/t7avlKtDdm/oBohbrc0QC83qK46QwaV6l3IotueZrMYSDNKjOQiy6Ro9nBqXyU3e0Z+RgyR\n+WRmBrwaeCVwLLAT+Brw9kmOeQHw18AjgE7gduALwHvdfb+Rq2Z2PPBW4AnABmAP8EPgPHf/XaHs\nhcCLU1ueBrwMOA74hbufeeD3VEREFoMl2yEWkYPaB4HXAfcCnwBGgGcCpwBtwHC+sJl9GjgHuBv4\nL6Jz+xjgXcATzOxJ7j6aK//kVK4V+B/gFuBI4NnA08zsLHe/pk67PgScBnwL+Dawf15VgZlNNI3E\n8VMdKyIiB4cl2yFet+EoAEYG99W2DQxFBLW1LSK9Hd0rsgNqU7GlqG5unt/KaERXx6oh1VyEuNQa\n5TvbY+7gllI2JVslRWUHUg7x2Fg2J3Ip1WW58m1t3dHm4cF0neUXV6dzc4+odm8u2jw4EOVKLftn\nwAylKd+GB6rnzuUNm6YflvlnZo8jOsO3Aie7+660/e3Aj4HDgDty5c8mOsNfA17k7gO5fecC7ySi\nzR9K21YDXwL6gdPd/YZc+YcAvwA+BZxYp3knAo9099tn596KiMhioBxiEZlvL0nX/1ztDAO4+yDw\n93XKvx4YBc7Jd4aTdxHpFi/KbftLYBXwznxnOJ3jeuCTwCPN7MF1zvWe6XaG3f2kehfgpunUIyIi\nC2fJRohF5KBVjcxeVmff5UTnFwAz6wIeDuwA3mD1f9UYAjblbj82XT88RZCLHpiuNwE3FPZdNVnD\nRURkaVqyHeLRlE44Usktz+xxd/v7d8d1387avlKauqx7eaRTjA5n05MNpbSL0TSAzuos+VxNPzjk\nkKNr+4bHYltLZ6RVjIxmaRiDKeVhYKCntq01DaJraYnp3cZNkVaJYH45LRvdkpvCbfXaZan+NMBv\neDh3XGpnmmLNcuke5TopFiLzoDrydGtxh7uPmdnO3KbVxKrp64nUiEasTdcvm6Lcsjrb7mvwHCIi\nsoSoRyQi821vuj6kuMPMymQd2nzZX7u7TXapc8zDpzjms3Xapsm5RUSa0JKNEJdbYoAalqUcjqVf\nYtvSohbLVq6v7WtNg+JGh2NBDu/LIrcdpYjKllIEt2tVdlw1BLt+dZzvtpturu1q6YxFNAZ69qSy\nWVsszRJlo9lAu6E0XVqlrSvdh2zAXfWn4qG+vel2tgDIQG1RkPgsHxvNZqAaHY1osZVSfyEXMR8e\nHjeQX2S+XEOkTZwB3FbYdxq59yV37zWz64GHmNmafM7xJK4E/jTV9dvZafKBOeGIlVy9iCamFxFp\nVooQi8h8uzBdv93M1lQ3mlkH8K91yr+fmIrtAjNbVdxpZqvNLD9jxGeIadneaWYn1ylfMrMzD7z5\nIiKy1CzZCLGIHJzc/QozOx94LXCdmX2FbB7i3cTcxPnyF5jZScCrgFvN7LvAncAa4P7A6UQn+BWp\n/E4zew4xTduVZvZD4HpiWZujiEF3a4GOub6vIiKyOCzZDnGlEgPMOpZn6Q3tyyNlsa0j0iNKuWzB\n0ZSuMDwcaRXl1u7avmXL1wEwllZ569mefV6v7Y60huHeOF9Pb5ZqQV+kSoyORKrE2GiWotDeGikM\n5XI2OK61PVIzxsbS4LjB/AxTkSJRXSWglBttP5YG0/lwbMunU7S3RwCulAbjtaf7DjDmWqpOFszr\ngZuJ+YNfTrZS3duAa4uF3f3VZnYJ0el9IjGt2i6iY/xe4D8K5X9oZg8D3gL8EZE+MQzcA/wI+Oqc\n3CsREVmUlmyHWEQOXu7uwEfSpWjjBMd8E/jmNM6xGXhNg2XPBs5utG4REVlalmyHuNQWA+dKLdld\n7OiOKdXa2iIqW7bc3U/Z1BWvRluzgWkDA/+fvXuPs6uq7///+pxz5j6ZSSZACAESQC5RFCQKilWC\nt6q01Vr9aq2taG9WrfXSVrRag18vfHvxXqWt9Vot2h9a+/VSab8KKkiVi1AggEAmQEjIfSaZ25lz\nzuf3x1r7wsmZyUwyk8mc834+HsOes9bea689nMfMOp981lpxV7hYNjBwTFr31HNOBeC2e3cCsPJx\nT0rrqtW4nGo81nIRYovR5vzc+GLc9S5ZUs3j8muQWz4tLvn2mNVY40S5WjW0X6lmu80WiiGC7bWk\nD+kSr1Sq2fciIiIirUqT6kRERESkpTVthLg6EVZn2rdzKC3bFZdUoxZzbQvZ54FKNYRgy5NxObTc\n5hvdXSHKWovXnb/uzLTu5BPCkqnf/O6P4o2zzTTa2uKPtxTzf3MR4snxEQAmRkfSsvJkuGeS55ts\nEgLQ0RGWYvNCzA8uZDHiWiVEhCfGw71rubBzW3tcMq4YyjwXFR6Lm4OIiIiItDJFiEVERESkpWlA\nLCIiIiItrWlTJixOTOvq7U/LKuWQdtDRESavFdqzJc9qcZpaIaYiWC7twOJurskktFNXr0rrklSG\nJStCWXsh+5EWLFw3OTkZ28yWOavF3eTGR/fl+hDTNOKSatXc5LiJmNJRm6zEPmWSTzXFuLRaqZBN\nxiu2JUuxhdeeq+vszXbCExEREWlVihCLiIiISEtr2ghxd19YGm1sfzaprnNJmKzW2RU23ah6/ooQ\njc2WYss+KxRiRLkjzmdbtfK4tK4YI9EvfOZTANi1a29ad8PNGwHwGJ5ty+0EUiiG9jt6sp1ok6XV\nOmNZ/zEr0jqLy8e5h+vyk+PGx8JkwfLEeGwnm9iXRI0nJ+IycrXcQ9e0MYeIiIiIIsQiIiIi0tKa\nNkIc03fxXES0FqPA5Zi/25bbNtliFHf/vhDhLRWzzwqT+0LEddXyPgBOOPb0tG7vUGjrtGND9Pk5\nT8427bjwvNUA3Hlf2LTjf+66N63bsy/mEE9k2zMn/ZsY2QPAjvEs2kwxhKdrMa+4NjmeVlXi81Qm\nQj9H92dtViZDFLgYc6Pz2zVXK1mOsoiIiEirUoRYRERERFqaBsQiIiIi0tKaNmWiRkgxaOvoTcsq\nSbpBnJBWKeZ2o+sJ53UvWQbAWSd0pXVPPH0lAMcuDWXLe7Oly8aGdgEwvP0BALwvmwj31LVPAuBF\nz10HwM7dT0vrbvr5fQDcefeWtOz7/30nAGUP/1ssP7EvpnB09oQ+eK6uUgnpEz4Znq93IPs5FOJu\nfHEuHuVKNuHOK9nEPBEREZFWpQixiCwKZnatmfnBz3zMNW5m185Tl0REpEk0b4S4GB6tpz+L9BLL\nqMXIaG7CnRXDJhUFC5POlg/0pHUvuDhEdrs6QnT1rtt/ntaN7NoEwMmrwgYg5dw8tXtv/RkAG28N\n53cvzSbcjewOy8Hd+rOfpWWdXccD0B6XciuXs4lzyffVuJFHMfdZxqtlAIZ2bwttD4+kdYVisuFI\neK5k8iBkm3yIiIiItLKmHRCLiABrgdGFuvkdW4ZYc9m3Z3Tu4BWXzHNvRERkKhoQi0jTcve7F7oP\nIiJy9GvaAXF133YAtu7ampZNToaUh86eJQBY/oI4+ay9ECbj9a19alrV2RUm0W28K0yc274nS0lY\nuiykVpTiTnIPDGb327U7rAdcroSUhm2P/jitu+3usDbx9pEsbaN3WTivFtcM7ujM0jY6e0JKRntn\nmPxXKGVrKE/GNYmXdy8HYFkte7JinIxXtZDL4bnd6bycrVcsspDM7NeAPwEeDwwAu4BfAF9190/V\nnVsC/hx4LXAysB34CvAedy/XnevAde6+Ple2AXgvcDGwGngLcBawD/gW8C533zbnDykiIkctTaoT\nkQVlZn8AfJMwGP6/wN8C3wG6CIPeel8B/hj4EfBpYIwwQP77Wd76rcCVwG3AR4F74v1uMLNjZ/0g\nIiKyaDVthLjYuxSA/s6+tMyrIRpbaAsR36IV07panExXiEuRVcayKPDQUNgx7ns/uQeAiTiRDmDF\nMSFi+8DmzQCMjmfR2Ue2PRq+iVHnSc8ivj2PewIAj+s/LutfjGBbDHLVPJv0VqnGyG48VnPLp5HW\nhessHwWuxc88tRAhrpQn0rqJiQVLrRTJ+0OgDJzj7tvzFWZ2TIPzTwOe4O674zl/QRjU/o6ZvXMW\n0d0XAhe4+625+32EEDG+AvjdmTRiZjdPUXXWDPshIiILTBFiETkaVIDJ+kJ339ng3Hckg+F4zgjw\nZcLvs6fM4p5fyg+Gow3AEPAqM+s48BIREWlGTRshnqh2AtBWzKLAhc4kMpwsRZZFc5PvCzFq/P1b\nH0jrNu/6FgDbJ0Kb+3dk99k0Fv5mjnM6AJX2rM3q8aGsFvN420vZhh4QItBeHk5L3MJ5k0kOcCUX\nwY7R7ZqHOvdS7rp4fltSluUlV+PSch6XmisUsj50tueWpBNZOF8mpEncaWZfBa4Drnf3HVOcf1OD\nsoficdks7ntdfYG7D5nZz4GLCCtU/PyAqw68Zl2j8hg5Pm8W/RERkQWiCLGILCh3/zDwGuBB4M3A\nN4BHzewHZnZAxNfd9zZoJskvKjaom8qjU5QnKRf9s2hLREQWMQ2IRWTBufsX3f1pwHLgEuCfgGcB\n3zOz46a9+NCtmKL8+Hgcmqf7iojIUaZpUyYKoyHIkyy1BlAj2a0tBJE8v/BaIU64i2mDbR1Z+uDt\nm0K6YiGmPBRKvWnd/t1h5zh8f6jL9aFUCq/aLOyCVxvPJrsVCW1Va9nWdrWY1lCpxglwlayuUArp\nGpakgHiuLk4IrExOxGM2Ga+athVTLqq5NE3P+iNyNIjR3+8A3zGzAvA64JnA1fNwu4uAL+YLzKwf\nOBcYBzYe7g3OXtXPzdpwQ0TkqKcIsYgsKDN7QVxbuF4SGZ6v5VB+28yeXFe2gZAq8S/uPnHgJSIi\n0oyaNkJMjKgW27rToqLHKHAxRGctN+HO0ol2pViXix7HiHIxmXiX+xzRNhmiv9Vq+NuZj7la3Dyj\nUAxHtyyqOzEeJtVVJrO/9R6XWSvGsUEhF8G1uBxcqdD+mHMBxob2ADC+P6RWVipZnZXC+aWO8PNo\nzz1z/jyRBXQVMG5mPwYGCXvmPBN4KnAz8F/zdN/vAteb2deArcAvxa9B4LJ5uqeIiByFFCEWkYV2\nGfATwooMbyBsjtEGvAO42N0PWI5tjnwk3u9cst3qPg9cWL8esoiINLemjRB7MUSGk6XMAIrxey8k\nxyxaGlczS5dfyy9rllRadlJalWyhXGgLm25YLrBcixHe5EjMJQYgLgHX3rk8u016DP3Kby3t1RDN\nLcc8Yy9k0d1iX7h3W3eYI1SsZLvX1srjse/Jo2StWmm+xhkiM+fuVxJ2jDvYeeunqfs8YTBbX24H\nnDyD60REpLUoQiwiIiIiLU0DYhERERFpaU2bMjFZjikFubSIShz+W7JDXS41sVSKP4q4q1ypkKUd\npBkSMd3Acp8j4jy9NL3Bcv9C63FptMp4mDg3OpztQjs+EpZyG9mX7VQX5+5RjJP+Crm+J/0rxAl3\ntdzsvWS5tupEmNg3Wckt7xZ3ryu1d8RHyO3O95id80RERERakyLEItJS3H2Du5u7X7vQfRERkaND\n00aIjRD9LeSWJ6vVkohrjAKXsscvxGhuweOmHbUskjpZDWHgtvjxYWL/7rTOi3F5t7gJR9FyO8fG\nJc+SHpS6etKq3rZwXUfvMdn5aSQ6Lq1WyPpnyfcxQpyPRCcRYqsduNGGxYmEhXhOrZqdU61p2TUR\nERERRYhFREREpKVpQCwiIiIiLa1pUyZqtThhrpBfhzimCyTpBtUsZaBSC2kRlXI4Lu/KUgsGli0D\nYNuuMDmuWMl2dG3vDpPVRmr9AJRzqwcXiZPWkuWHi9lOdR7Pa8+lbSTJFhbTN6w2ntZVJ8LOdqPD\nIV2jHHe6A6gl6SExnSK3wR1tceKcx8mCnswCDC8QERERaXWKEIuIiIhIS2vaCHGhGCK35Haq88Jj\nlzOr5aK5Voy7ypXDcmsd1Wzn1pW9XQDs3L4vFJSyNjsqIYo7OrkDgKJlUVcfSSLSIaJcnhhL66px\nN7mx4T1pWa0W/ncU20M/u5cMpHXdfUsB6OxdErrQuSRrqxqeoxqj4lXPItGV2J1CNZTVcuHjA6fg\niYiIiLQeRYhFREREpKU1bYS4FnOCzfIR0cpj6jy38UWxGKKsSXpxf3+2RNo5a1cDsHX3/wAwNJJF\nlnsLIeq749HBcH2xPa0bHU/XUQOgvbMzrWvv7AOgY8nxWf88yQEOkV7L9W/Ck000DnyuUimWVcP5\nxVxqcK0WI8Pxs0+hkFWaK0YsIiIiogixiIiIiLQ0DYhFREREpKU1b8pEzH1wzy27FlMXinECXYls\n8pnFbyfj5LOhcldad8fmsMTZkiVhabXuYm4i3ERo65QTwtJsXbnJbsW41JlVhgDYO5Yt17Z5a2hj\nb7kvLetecXposxgn/+VSH6wa0yjSPmd9L3iYoIeHczy3A53FpdUKMdWiRlbnucl3IkcDM1sDbAK+\n4O6XzuD8S4HPAa9198/PUR/WAz8ALnf3DXPRpoiIHN0UIRYRERGRlta0EeKJuHxaqZiPEIfHTSaY\nUSzmrohlHWHi26OjWSR19P4Q4e3vCku5Lc9FgbePhjY3DYeyM/rb0rqlxbAk2+PPCBPnSoUsIvuf\nP94IwK6HRtOytkKc5FYL96tWy2mdxUXSCnE+Xyk34c7j5LgKyYYeuchvjDLX4rYfXs2uq2lfDln8\nvgHcCGxd6I6IiMji1bQDYhFpfu4+BAwtdD9ERGRxa9oBsZdj5LW9Oy1Lt1VO8oqzIDDFJPQalzOb\nzEVgh8dCKHXr7nDBucdny5W1x2jsmiV7ATi9L8s97iyEnOE9e0IO8tBwFg3uaA996ChmZZWJnbEL\ncVm4Sn5r6XCfYluIUntbFvmuJlHgWlt8nf1vrdXihiPx+vxKa4oQy9HMzM4CrgCeBXQAtwLvc/dr\ncudcSoMcYjMbjN8+CdgAvBRYBXwgyQs2sxXAB4FfAfqAe4CPAJvn7aFEROSo1LQDYhFZ1E4BfgLc\nAfw9sBJ4BfBdM3uVu391Bm20A98HBoBrgGHChD3MbDlwA3Aq8OP4tRK4Mp4rIiItRANiETkaPQv4\nG3f/s6TAzD5JGCRfaWbfdffhg7SxErgLuMjdR+rqPkQYDH/U3d/a4B4zZmY3T1F11mzaERGRhdO0\nA2JrC5PcJnN5ARYnqVWTyWfZhnNU4mkWlyJb0pmlTDzh9BMA6CyEZc1qE9nyaT21fQDsKYe/zT+/\nK5sIt2c4fF+JS6YlS7oBjI6F3IXRkSwtomoPhzaXhPu19SxL64oxzaMan2eimj1X+m1Mj/DcpLrk\nll6JS8Dl1xVx5UzIUWsIeF++wN1vMrMvA68Bfh34wgzaeXv9YNjM2oDfAvYR0immuoeIiLQILbsm\nIkejW9x9X4Pya+PxyTNoYxy4vUH5WUA38PM4KW+qe8yIu69r9AXcPZt2RERk4TRthLjo+wGYGMsF\nhyohUlsohc8B7lmI2D1EhEul8COZbFua1t2/bQyAcgwjl8fa0zqzk8L5MWpcKY+ndW3d4bxanORW\ny4Wki72hL90D2Sy3QjFMmBuPy8GNjueXTwv3tjgrrkB2ncW11SzOEiyQRbCZDGOKseHd4eVkVpdO\nJBQ5+jw6Rfm2eOyfQRvb3Rv+M0hy7cHuISIiLUIRYhE5Gq2Yovz4eJzJUmtT5QQl1x7sHiIi0iI0\nIBaRo9F5ZrakQfn6eLz1MNq+GxgFzjWzRpHm9Q3KRESkiTVtykSyJm+xfXla5u0hJaEW1xi2XApD\nIaYP1OIxWx0YxnaHNIjOUqjrbMsm3JVimmPFwgS6Ylu2U51PhuvaO8J9S/H+ABUP31drubSN+L0n\n6RCN4lvxX4AL+QWFPUmtCGXVSnZhspRxe2d/7ENWl2tB5GjTD/wlkF9l4imEyXBDhB3qDom7T8aJ\nc79PmFSXX2UiuYeIiLSQph0Qi8ii9kPg98zsAuB6snWIC8AfzmDJtYN5F/Ac4C1xEJysQ/wK4DvA\nrx1m+wBrNm7cyLp16+agKRGR1rNx40aANUfiXk07IL7zR1drxpjI4rUJeD1hp7rXE3aqu4WwU933\nDrdxd99pZs8g7FT3q8BTCDvV/REwyNwMiHvHxsaqt9xyy21z0JbIXErWyNZKKHK0qX9vriFsqjTv\nrPEkbBERORzJhh1xCTaRo4bem3K0Wsj3pibViYiIiEhL04BYRERERFqaBsQiIiIi0tI0IBYRERGR\nlqYBsYiIiIi0NK0yISIiIiItTRFiEREREWlpGhCLiIiISEvTgFhEREREWpoGxCIiIiLS0jQgFhER\nEZGWpgGxiIiIiLQ0DYhFREREpKVpQCwiIiIiLU0DYhGRGTCzE83ss2b2iJlNmNmgmX3UzJbNsp2B\neN1gbOeR2O6J89V3aW5z8d40s2vNzKf56pzPZ5DmY2YvM7NPmNmPzGw4vo/++RDbmpPfv9MpzVVD\nIiLNysxOA24AjgO+CdwNnA/8CfACM3uGu++aQTvLYztnAN8HrgLOAl4LXGJmT3f3B+bnKaQZzdV7\nM+fyKcorh9VRaUXvBs4B9gMPE37Xzdo8vMcb0oBYROTgPkX4Zfxmd/9EUmhmHwbeCnwAeP0M2vkg\nYTD8EXd/W66dNwMfi/d5wRz2W5rfXL03AXD3DXPdQWlZbyUMhO8DLgJ+cIjtzOl7fCrm7ofbhohI\n0zKzU4H7gUHgNHev5eqWAFsBA45z95Fp2ukBdgA1YKW778vVFeI91sR7KEosBzVX7814/rXARe5u\n89ZhaVlmtp4wIP6yu796FtfN2Xv8YJRDLCIyvWfH4zX5X8YAcVB7PdANPO0g7Twd6AKuzw+GYzs1\n4Jr48uLD7rG0irl6b6bM7BVmdpmZvc3MXmhmHXPXXZFZm/P3+FQ0IBYRmd6Z8XjvFPW/iMczjlA7\nIon5eE9dBXwI+FvgO8CDZvayQ+ueyGE7Yr83NSAWEZlefzwOTVGflC89Qu2IJObyPfVN4FeBEwn/\nknEWYWC8FPiqmb3wMPopcqiO2O9NTaoTETk8Sc7l4U7ImKt2RBIzfk+5+0fqiu4B3mVmjwCfIEwI\n/e7cdk/ksM3Z701FiEVEppdEIPqnqO+rO2++2xFJHIn31GcIS66dGycxiRxJR+z3pgbEIiLTuyce\np8pROz0ep8pxm+t2RBLz/p5y93EgmQTac6jtiByiI/Z7UwNiEZHpJWtnPj8uj5aKEbNnAGPAjQdp\n58Z43jPqI22x3efX3U/kYObqvTklMzsTWEYYFO881HZEDtG8v8cTGhCLiEzD3e8nLIm2BnhjXfXl\nhKjZF/NrYJrZWWb2mF2Z3H0/8KV4/oa6dt4U2/+e1iCWmZqr96aZnWpmq+rbN7NjgM/Fl1e5u3ar\nk3lhZm3xvXlavvxQ3uOH3AdtzCEiMr0GW4duBC4grBl8L3BhfutQM3OA+k0OGmzd/FNgLfBiYHts\n5/75fh5pHnPx3jSzSwm5wtcRNkHYDZwMvIiQu3kT8Dx33zv/TyTNwsxeArwkvjwe+GXgAeBHsWyn\nu/9pPHcNsAnY7O5r6tqZ1Xv8kPurAbGIyMGZ2UnA+whbKy8n7JD0b8Dl7r677tyGA+JYNwC8l/CH\nYiWwizB7/y/d/eH5fAZpTof73jSzJwJvB9YBJxAmKu0D7gS+Bvy9u5fn/0mkmZjZBsLvuqmkg9/p\nBsSxfsbv8UPurwbEIiIiItLKlEMsIiIiIi1NA2IRERERaWkaEIuIiIhIS2u5AbGZDZqZm9n6he6L\niIiIiCy8lhsQi4iIiIjkaUAsIiIiIi1NA2IRERERaWkaEIuIiIhIS2vpAbGZDZjZh81sk5lNmNkW\nM/tHM1s5zTUXm9nXzWybmZXj8Rtm9uxprvH4tcbM1prZF8zsITObNLN/y513nJn9tZndYWYjZjYe\nz7vBzN5nZqunaP9YM/uQmf2Pme2P195hZh+Iu2KJiIiIyBRabqc6MxsEVgO/Dbw/fj8KFIGOeNog\ncJ6776m79v3AX8SXDgwR9nlPtsC8wt3f2eCeyQ/5d4ArgW7CtphtwPfc/SVxsPsTwlauAFVgGFia\na/+P3P3KurZ/ibC3dzLwLcdru+Lrhwh70N8zzY9FREREpGW1coT4E8Ae4EJ37wF6gRcDe4E1wGMG\ntmb2SrLB8CeB49x9GXBsbAvgMjN79TT3/BTwM+CJ7t5HGBi/Pda9lzAYvg94FtDu7gOEge0TCYP3\nbXV9Wg38X8Jg+DPAWfH8HuBs4D+Ak4Cvm1lxJj8UERERkVbTyhHiR4EnuPuuuvq3A38DbHL3U2OZ\nAfcCjwOucvffbNDuV4DfBDYDp7p7LVeX/JAfAM5297EG198FrAVe6e5fneGz/DPwW8DH3f1PGtS3\nAz8FzgFe7u7/30zaFREREWklrRwh/of6wXCU5PSeYmY98ftzCYNhCJHaRi6Px9XA+VOc88lGg+Fo\nOB6nzF/OM7Mu4OXx5YcbnePuZSAZBD9vJu2KiIiItJrSQndgAf1sivItue+XAiPAefH1Dne/s9FF\n7n6PmW0BVsXzb2xw2k+m6c93gAuA/2NmpxMGsjdOM4B+CtAev//vEMRuKMklPmmae4uIiIi0rFaO\nEO9rVOju47mXOdGpTAAAIABJREFUbfF4bDxuYXoP151fb8c01/4f4N8Jg9w3AN8HhuMKE39mZkvr\nzs9HkldM89UXz+k+SN9FREREWlIrD4gPRcfBT5lWdaoKd59w9xcDTwf+ihBh9tzre83snNwlyf+7\nPe5uM/haf5h9FxEREWlKGhDPTBLZPfkg551Yd/6sufuN7v4Od386sIwwUe9BQtT5M7lTH43HZWZ2\n/KHeT0RERKTVaUA8M7fEY4+ZNZwwZ2ZnEPKH8+cfFncfcfergD+IRetyE/1uAirx+5fOxf1ERERE\nWpEGxDPzc8L6wADvmuKcDfE4SFjqbFbiEmlTSSbWGXEinbvvA66O5e82sxXTtF0ys97Z9klERESk\nFWhAPAMeFmt+d3z5YjP7hJktBzCz5Wb2cUJqA8C782sQz8IdZvZBM3tqMji24HyyjT9+Vrd73mXA\nbsIEuxvM7NfNLM1zNrPHmdlbgI2EVSlEREREpE4rb8xxsbtfO8U5yQ/lFHcfzJXnt26ukW3dnHyw\nONjWzY9pr+6cvbEtCJPvhoAlZCtd7ASe4+631133VMLaySfEokq8tpfHTgJc7+7XNbq3iIiISCtT\nhHgW3P3dwHOAbxIGqL3ALsJyac9tNBiehRcDHwKuBx6JbZeB24ErCLvq3V5/kbv/jLBl8zuAGwjL\nyS0lpFncRFjO7akaDIuIiIg01nIRYhERERGRPEWIRURERKSlaUAsIiIiIi1NA2IRERERaWkaEIuI\niIhIS9OAWERERERamgbEIiIiItLSNCAWERERkZamAbGIiIiItDQNiEVERESkpZUWugMiIs3IzDYB\nfcDgAndFRGSxWgMMu/sp832jph0Qv/hlv+oAAytOTMu8UAVg59ZNAFQnsm2rCxbqOksGwJKe7rSu\n6hMA7B8bAiCeAkDfkv5wXWc43+hL68qV0H6lOg7ARHl/Wrd7zw4AxsvlrA+lDgD6ewcA6OnO2qpW\ni6GNsQoAbZZ1orM91PV2tQFwysmr0rr++BwPbtkGwODWnVn/4uNf9dV/zT2RiMyRvq6uroG1a9cO\nLHRHREQWo40bNzI2NnZE7tW0A2IRObLMbA2wCfiCu1+6oJ05OgyuXbt24Oabb17ofoiILErr1q3j\nlltuGTwS92raAfG+/Q8DUPZ9aVkpRlInJ/YAULRiWtfTHSKpSzqXANDZ3pHWWSH8mAqFcmx7NK3b\ntjNEXDt7w3UDy/rTumXHHgdApRoizPf+4o60bsfevQC0tWVp3B0x6js5HiLJk15J6yqT8ftyLZzb\n1ZXWHdMdAlDdnaGtpZ1Zm93tIQzcSeiDTQyndSP7j8ynLhEREZGjWdMOiEVEFtodW4ZYc9m3F7ob\nIiILYvCKSxa6CzOmVSZEREREpKU1bYS4Giew7culCBSKYdJZR1s7AKWOfEpC+FFMlkJKQjwlnFcI\nL7o6lgFgnqVT7B2KE+UmQ7rDnp1bsj6MhLSIdMbayHhad+qxJ4X7VrJJde3F0IeumKLR25mb2NcZ\nUh8K1dBawXKpFoXwfVd7Z+h7R3ZdR28vACecvBqAYm6i3tCIUiZkfsR84iuA5wK9wB3ABnf/Vt15\nHcBbgVcBjwMqwG3AJ9z9aw3a3AR8Afgg8L+Bi4FjgGe7+7VmdipwGfBsYBUwBmwBrgf+wt131bX5\nm8AfAOcCXbH9LwN/7R5n04qISNNr2gGxiCyY1cBPgQeALwEDwCuAb5rZc939BwBm1g58D7gIuBv4\nO6AbeBnwVTM7193f1aD904D/Bu4lDF67gGEzWwn8jLDU2XeAq4FO4BTgt4FPAumA2Mz+CXgd8DDw\ndWAv8DTCQPs5ZvY891wiv4iINK2mHRB3diwFoFrJLa1WCBHivr4QJe3pyyK9pUKIrna1hehqT282\naa2jPUSI29rC9dlUPLBKJV4fSj1XW4gZKckKaU8+65y0brIyGdrqyELRnoSSq3EJuM7erH9J9LeY\ntJlFiGOAmLa2GGHu7sldF/rT3h9+Hr0rVqZ1lZpWW5N5sZ4QDb48KTCzrwD/AfwZ8INY/HbCYPi7\nwK8lg08zu5wwoH6nmX3L3W+oa/+XgA/VD5bN7I8Jg++3uPvH6up6gFru9aWEwfA3gN9y97Fc3Qbg\nvcAbgce004iZTbWMxFkHu1ZERI4OyiEWkbm2GXh/vsDdvwc8CJyfK34d4MDb8pFYd99OiNIC/F6D\n9h8FLm9QnjggF8jdR/KDXuBPCOkZr6srJ957F/Bb09xDRESaSNNGiJ92wUUAtJWyiG1bjLIuPyZs\nXFHKJQpXKkl+b4z4lrIfTWdXiBq3xwjxxP69ad3wjq0ATE6Ev6k9MRILUGsPbVRjm5b7aZeqoS+r\nT3hcWrZ58B4Adjwa2hwfzzbR6I55zJ3LQtS4sDRb3q0cA72FGAwfrWZ/331/iETXajE3upRFxWsF\nfR6SefFzd682KH8IeDqAmS0h5Axvcfe7G5z7/Xh8coO626bI7/13Qm7x35nZLxPSMa4H7nL39J+K\nzKwbOAfYCbzFrOG/lEwAaxtV1HP3dY3KY+T4vJm0ISIiC6tpB8QismD2TlFeIftXqeQT3dYpzk3K\nlzao29boAnffbGbnAxuAFwAvjVUPmdnfuPvH4+tlhLmuxxJSI0REpMUpRCgiC2EoHo+fon5l3Xl5\n3qAsVLhvdPdXAMuBpxBWnCgAHzOz361r81Z3t+m+ZvVEIiKyaDVthPi8884FoFDI/naOj4d/ZW0r\nhnSFzo7cbnTFMBFtz75kEnr2L75tFna727d9NwCDt9+e1u3esjncJ87X6RtYltZNtocUi55lYce6\nx5+TpU92dIUAWWVPtpPelptDu5vvuDP0YCxbpm1pX5jkt/T4sCvdKU95Wvasz3wuAP0DYWxRKmb/\nW5OsiGT+XKGYpZCYPg/JAnH3fWZ2P3CqmZ3u7r+oO+XieLzlENuvADcDN5vZDcAPgZcA/+Tu+83s\nTuAJZjbg7rsP8TEO6uxV/dy8iBamFxFpVRoRichC+SwhdeGvzbJ91M3sGOA9uXNmxMzON7MVDaqS\nstFc2YeBduCzZnZAWoaZLTMz5f+KiLSIpo0QPytGTXPbYqTR0j3bHwHgwfuzuTynn/kkAJYsWw7A\n9kc2p3V3/vQnAGy+KURwH773rrSuzcOkteOOCZHh6u4sfXLfrhD9nejdDsDGHVkgKtkkZGR3VjY5\nEs5fEv+vjOai28l9SqNhI5BHbsui1CeeeHo4Hn9ieOJcFLgaJ+97XMqtOp5FnScn4rykk85EZAH8\nDfBC4MXAbWb2HcI6xC8HjgP+yt1/PIv2XgW80cyuA+4D9hDWLP5VwiS5jyYnuvtnzWwd8AbgfjNL\nVsEYIKxb/Czgc8DrD+sJRURkUWjaAbGIHN3cvWxmzwPeRhjM/jHZTnVvcfd/mWWT/wJ0ABcSVnfo\nIuxSdxXwt+5+R93932hm3yUMep9LmMC3mzAw/mvgnw/x0UREZJFp2gHx+PAeALp7suXJJishIjoa\n6+677da07qF77wXAayGS+sDtN6V12zdvAqASo6s9HfkfW4ji1mJdqZRFpHu7w3m1Wqjb89ADB/Sz\noz3LY+5oC9cW+2OOc1vW1mRsfzweqxOPpHXXf/NfAdj6cIh45/OYqx5ym2sxUu7p1gRQjVHjM85+\nxgH9Epktdx8k/08yB9avb1A2Tlgq7YNz0P5/E3awm7G4lfS3DnqiiIg0NeUQi4iIiEhL04BYRERE\nRFpa06ZMXPfNzwGw4qST0rLJakg3mBwPqQIjw7vSupt/8L3wzdgIAIVaNqGtENMiSvFfa0eGs4lp\nlUqomxgJk956ezuz69rCj7ctLu9WKGafP5KNs2qVbHm3sfHQRrJzVltut7xK3OZubCycg2W5Dz4c\n+rzi+FMAeMIFF6Z1VmqP9w7XF/O70zXeoUtERESkpShCLCIiIiItrWkjxDseHARg1emnp2Xd7cly\no+FzwNjIWFq3e1OYkFYdChHY0bFKWrdvpAzAxEQoq1ZyG2XFzazKcWOOcjm7rjNGiJNocHIEqMXJ\ne7VKOWuqGq6txYh0oZD97ymWQp+TiXAFy9oqxWXWunrC8/UszTb/KsRJe4WCHdCHaTb8EhEREWkZ\nihCLiIiISEtr2ghxe1fY4vis856TlnX2hOXIhnZvBWDXo9vTumUrwmZWwx4isHvHsw02hmJkuDYZ\nosCF3NJlxRhlNUKUtr09+5G2xwjx2HiIRBdyOcFJfnCtlkWUk/TeQiG0Va1l+cXJPl6dcTtor2ad\n6OwMZV3d3QCU2rKNOTy2X4nnV3I5y0m0eVm2Mp2IiIhIy1GEWERERERamgbEIiIiItLSmjZlwtrD\ncmPVXGpBrRImzO16dBsAu7dtS+tWnHAiAEPbQ9lkOZvslnxqqMaJaY9JZYjLs5XiBLhSKfuMUS6H\n5dnKE2GHvJ72vlybsa3cJLyOztDnUky1mJjI+lCJqRzFWFfObdg1Eh/xlo33AbBpf9a/ZOe9Snz2\nSiW73/hY6Ncb/vANiIiIiLQqRYhFREREpKU1bYQ4ifj29C5Jy4oxitvV3QNAd9+ytK68L0RQJ2vJ\n0mqTaV13d5h1tt/C54fa2P60zuKEOY8fLfIR6YkYIbYYzS0WsqhuEj12z6K5xWSiXbxPuZoti7Z3\nJERzi3Hzjra44QZAqTP04cEH7gzHRwbTulpcys1IjplkIqCIiIhIK1OEWERERERaWtNGiLsGVgJw\n35YdaVk15uTuGxoCoNSdRY9Hd20J58Stm8u5XNuuE1YBsGrNGQBsvuvWtG7fw4MA9BaTH2Vu8424\nTJvHssmYSwxQnghR3fZcznHc44PJZCOP7iznuHNJWBbOJ0NkuVjONhVZuiI869KT1gDQ3b80rRtY\nGqLgxy5fDsCy3BprPT29iIiIiLQ6RYhF5KhiZm82s7vMbMzM3MzestB9EhGR5ta0EWIRWXzM7JXA\nx4BbgY8CE8CNC9opERFpek07IP7pbf8DQOUXD6dl4yOjAFQnQ+rE6v5sUlnPeKirjIaUhEpuctz+\nsZB24bvDRLZJy+r2xGXTSnvDdZ3FnrSuLd2ZLuRCFCxLp2iLO9qVilkfynEin7V3ALD2vKemdede\n9CIABjf+HIC7f/KDtO6CZz0TgKe84Ndj2x1pXa0S+lqbDP0cy00IHBkdRuQo8yvJ0d0fWdCezIE7\ntgyx5rJvAzB4xSUL3BsREZmKUiZE5GhyAkAzDIZFRGTxaNoI8SP3h0hqzbKFxvbuD5HhsXKImh57\nzhlpXX8p1CWLoLUNHJ/WtR17cmirI0R/l6/KJq1VRuKGF3FS3vB4tpnGsiWdALTHSHGhO1sqbXIy\nfD9Uacv6sCREdvt7Qp+XL82izUv7usOxP0yE6+jMIstbt4QNOW68NkSidg9nkd/h3WEC4dj+EBke\ni5FwgNGxENX+0McvRGQhmdkG4L251+k/p7i7xdfXAa8E3g+8EDge+F13/3y8ZiXwbuASwsB6CPgR\n8AF3v7nBPfuBy4GXAccAg8A/AP8G3A98wd0vndMHFRGRo1LTDohFZFG5Nh4vBVYTBqr1Bgj5xPuB\nrwM14FEAMzsF+DFhIPx94F+Ak4CXA5eY2W+4+7eShsysM553HiFf+ctAP/AXwDNn03EzO2CwHZ01\nm3ZERGThNO2AeM1pjweg0N6Vlm1+dB8Ao2NhybK29u60bmz/HgCKfccCUGs/Ja0b6QvfFwohKlvI\nLa1WXRKWadv+yKPh3Il9aV1HW4j09hwf7tN+3IlpXXvHcQCUitnSZ8fFVdYq28IGG49uujPr+5bw\nL8hDQzHSu2NnWrd9byir3L0p9L2Y/W9tK4UIdGd7OHZ1d6Z1Xd1ZdFpkIbn7tcC1ZrYeWO3uGxqc\n9kTgS8Dr3L1SV3clYTD8bnf/QFJoZp8Cfgh8wcxWu3uSRP9nhMHwVcCr3MNah2b2AeCWuXouERFZ\nHJRDLCKLRRn40/rBsJmdCDwfeBD4q3ydu99AiBYPAC/NVb2GEGF+ZzIYjuc/RFjdYsbcfV2jL+Du\n2bQjIiILRwNiEVksBt19e4PyJ8fjj9x9skH99/PnmVkfcBqwxd0HG5z/48PtqIiILC5NmzJx6Zv+\nHICx3O5wX7n6GgAe3vwQANaZLZ82Ph4+G1j/AACTY9mktb07HgxlE+FfW6ueTZwbH9sLwFAtBK3M\ns+t640Q4OkJqwkgtS1eYGA9/t/tOPC4tmyyF9odH48S3WhYI2zkU0jz2l8O0v1o560NnV2i/75jw\nDB2d2bJrbaUweS9J93DL2tw/mqV3iCwC26YoT7Zf3DpFfVKezIZNtoB8dIrzpyoXEZEmpQixiCwW\nPkX5UDweP0X9yrrzkmVYVkxx/lTlIiLSpJo2QrzzkQcA2LE925ijti8sT9bfFiKjkyPVtK5SDn9r\nH9gWNuEY3P1QWufVuHRbLflxZZ8jjBBx7eoKUdlOsqhzR0e4bs9wiFIPl7Pl0NacFoJUK5Zmk+qW\n9Ydl1sa3hOPe4aG0bji2O2YhMtxeyv5leLIQ6vaNxwl3E+NpXTsheuwWIsRVsme24lTjC5FF5dZ4\n/CUzKzWYcHdxPN4C4O7DZvYAsMbM1jRIm/iluerY2av6uVkbcoiIHPUUIRaRRc3dHwb+E1gDvCVf\nZ2YXAK8C9gDfyFV9kfD770Nm2WLlZnZSfRsiItL8mjZCLCIt5fXA9cBfm9nzgZvI1iGuAa9193zS\n/F8BLyFs9HGmmV1DyEX+X4Rl2l4SrxMRkRbQtAPir37xSgB27tmdlu3cG/4ebtsZ1g7OZwx0tIVg\n+VDczW6inEstiEePk9w8d11SVy2EyWs93VllW0coG6mE44N79qZ11S3hR9++bHVa1t0VzqvEG1gp\nm4TX3R7qLO4019aV/atwd0+cU1QIaRu1SvZ3vKerO/Yl1nlW566/99Ic3P0BM3sKYae6FwHrCbnC\n/0HYqe5ndeePmdnFwPsIO9W9FdgEfJCwu91LyHKNRUSkyTXtgFhEFh93Xz9FuTUqrztnC/BHs7jX\nXuDN8StlZr8fv90407ZERGRxa9oB8Q033wHAjr2jadlYOfxNLRXDRLOezuzxR8Ym4zkhMlyuZpHe\nJNG6GFMNi9nKasQN4OgbCJPjTl7an9a1dYcryyNhkltPf7Zr3p6hsNPcffffm5b1lk4AoL87TLir\n5SbOtbeHCO+SniUAdBdyu9F1h3arhdjTWn7skMa3AZjITbirVquItCozO8HdH6krOwl4D1ABvtXw\nQhERaTpNOyAWETmIq82sDbgZ2EuYlPcrQDdhB7stC9g3ERE5gpp2QHzBuWcA8LPb70/LHnwk5BCf\ncGyIqF7w5DPTuu4YZd2yfRcAmx7M1uZ/dEfI/S22hXDwmadly52uPC5c11kMkdjCnmwjrfZCKOvp\nDZHbLTuyZdTOP3ctAEND2TyfBzaGqPb5Twh5xWNjWTS3FOPUvbGfXR3Z5ht794U2qhMhouxkEeJa\nLeYjx9fJBh0AZrlQt0jr+RLw28BvECbU7Qf+G/iku399ITsmIiJHVtMOiEVEpuPunwI+tdD9EBGR\nhad1iEVERESkpTVthHjJkpDesPyYvrRs2+4wwW7F8aGsrz/7PFAshHSDNSeGSWsnrcgmx90zuC0c\nH4jzb2rZkmfLekIKQ3EyLNc2Op5NhBsnfH/a6lMB2Dq8Oa0b2xNWdHrCaSvTsp7OsLRa97LQh11j\nE7knCkkP3V3hfu25lAnfF3aoK8TPN7VcykSytFrM3qBUbE/rajUtuyYiIiKiCLGIiIiItLSmjRBP\nWojODgz0pGWrjw+R1xXLwmYVtWoWgfW4ApkRJpq1FbMo64qBEJW9fzC8vvu+h9K6gb6wecaqY8Ky\na8XOtrSuuj9EpNs9TI47dfWKtG7TA1sBWLo0W4pt1dowmW7f/jEA7o3nAHR1hHYH+sN92tqz/3XF\nODmuUggR31olW06tVokT7eI5hUL2GahSUYRYRERERBFiEREREWlpTRshbo+R3lNWDKRlJy0N35uF\nyGjRc5HUuElFeTJEjSdzHxWKhPP7ukOb7cVsS+VHtsStocvhnBVdWcS3UI7LpsW2TzkpixCP7w91\n9+WiwGtPCxHijlKIBvf3ZNHt3bvD0m/79oXocbWWbRwyMhbKSDbzyu0tbZY8SG6/aZJuaWMOERER\nEUWIRURERKSlaUAsIiIiIi2taVMmhnfFXeGq2cSxZBJZjWT3tlwaQZKCECedeSGbVFcshh/TKScc\nC8CWR3eldf39Ia1h11BYRu3UE05O68YrIf1iLC7F1jGZLcm26viQvlHMfSTZsjWkT3R1haXR+pZ0\np3VLesP31Wro59DwSO65QuqDx2fIL6eWfF8oNO3/ahEREZHDogixiIiIiLS0pg0b7tkTNqsoFYpp\nWbEUor4VDxtreDWLEBfM4jlx2bTcimRJrLi/N0yYGx3NJrvtHwmT3VauDBPmVq1ZndYNdYYr9wyH\nCXS1WhZ1XrIktNXZeWxaNjkZJ8yNxgh2Lnwcu85kjDpP5pZMq8YosCWPY9l9CsXw/En0uFzOotST\nlWyDEZFWZmbXAhe5ux3sXBERaT6KEIuIiIhIS2vaCHElbqVMKXvEaozQelyWrK2t7YDryuXyY84B\nqMbzisVwzOf2PrQt5BMftzzk8fb1Z9HjyckQNd49uiX0aWIsrbO2uIVyLo3ZPfY1BqmKVsrVhfYn\nq5XYdhbdrcY86VKMbucCxNTSvOJwrOSiwjU/cCk2EZk7d2wZWuguiIjIDChCLCKLipmdb2ZfNbMt\nZjZhZlvN7Boz+1+5cy41s6vN7AEzGzOzYTO73sxeXdfWGjNz4KL42nNf1x7ZJxMRkYXStBFiEWk+\nZvb7wKeBKvDvwC+A44CnAG8AvhZP/TRwF/BDYCuwHHgR8CUzO9Pd3xPP2wtcDlwKrI7fJwbn8VFE\nROQo0rQD4rY0zSGbVGf22PkypVw6RZo+kU5ey1ILkuuKcZJbb29HWrd0aX+oiykQ+yay3d+27wq7\n2Hlcyq2zO9vFLkmLqE1m57e3h3aTHeRGR0az09P0Bot9L+auC/dOdq+r5Zaam4xLvVVim/k0Ecst\nzyZytDOzxwOfAoaBZ7r7nXX1J+Zenu3u99fVtwPfBS4zsyvdfYu77wU2mNl6YLW7bziEft08RdVZ\ns21LREQWhlImRGSx+CPCh/j/XT8YBnD3h3Pf39+gvgz8XWzjOfPYTxERWWSaNkLc19d3QFkyoSyJ\n+Pb29qZ1aSQ51nlutlshRniTCPHYxERat3xZmER30sqwfNrkxHhaNz5RjvcN0dlqLiKbTIRLNwQB\n6ue4JRuC5NvIotzZZ5lkpahqGtXOIuGTMQI9OhaizZ2dWXQ7vwSbyCLwtHj87sFONLOTgXcQBr4n\nA111p6yaq065+7op+nAzcN5c3UdEROZP0w6IRaTpLI3HLdOdZGanAj8FlgE/Aq4Bhgh5x2uA1wAd\nU10vIiKtp2kHxIWYH9zVkf3dq3mIyraVDswvThRjbm6jBcmSCHHSDsBxA0sA6OsM1w3t3J7WjcQc\n4GLsSyEX1U2WQfNqPo83lsW6QjG/ZFxSF87Pb8xRKiVLq8VWcv0rWLhnV1d9gAxKDZadEzmK7Y3H\nVcDd05z3NsIkute6++fzFWb2m4QBsYiISEo5xCKyWNwYjy88yHmPi8erG9RdNMU1VQAzO/BTsoiI\nND0NiEVksfg0UAHeE1eceIzcKhOD8bi+rv6Xgd+bou1d8XjyYfcy5+xV/XPZnIiIzJOmTZkgLmGW\nTxUYS3avSyamFbLJZx0xtSKZtJbsWAfZMmie5iTkblMKnyl2DR24I1V7W/jxJjvc5T9/7Nu/PzaV\npTd0dITl09raw3nV3IS7apxxl6RD5CfcxTl1VGpxN7vcLnbJsmsdHeF8K2RpErVadp7I0c7d7zKz\nNwBXArea2TcJ6xAvJ6xDvA+4mLA022uBfzWzqwk5x2cDLyCsU/yKBs3/P+DlwNfN7DvAGLDZ3b80\nv08lIiJHg+YdEItI03H3fzSzO4A/JUSAXwLsBG4HPhPPud3MLgbeT9iMowTcBryUkIfcaED8GcLG\nHK8E/jxecx1wOAPiNRs3bmTduoaLUIiIyEFs3LgRwmToeWdev9aXiIgcNjObAIqEwbjIQko2iZlu\nMqrIkTDb9+IaYNjdT5mf7mQUIRYRmR93wNTrFIscKcluinovykI7mt+LmlQnIiIiIi1NA2IRERER\naWkaEIuIiIhIS9OAWERERERamgbEIiIiItLStOyaiIiIiLQ0RYhFREREpKVpQCwiIiIiLU0DYhER\nERFpaRoQi4iIiEhL04BYRERERFqaBsQiIiIi0tI0IBYRERGRlqYBsYiIiIi0NA2IRURmwMxONLPP\nmtkjZjZhZoNm9lEzWzbLdgbidYOxnUdiuyfOV9+luczFe9HMrjUzn+arcz6fQRY/M3uZmX3CzH5k\nZsPxffPPh9jWnPx+PRylI3UjEZHFysxOA24AjgO+CdwNnA/8CfACM3uGu++aQTvLYztnAN8HrgLO\nAl4LXGJmT3f3B+bnKaQZzNV7MefyKcorh9VRaQXvBs4B9gMPE36Xzdo8vKcPiQbEIiIH9ynCL+s3\nu/snkkIz+zDwVuADwOtn0M4HCYPhj7j723LtvBn4WLzPC+aw39J85uq9CIC7b5jrDkrLeCthIHwf\ncBHwg0NsZ07f04fK3H2+7yEismiZ2anA/cAgcJq713J1S4CtgAHHufvINO30ADuAGrDS3ffl6grx\nHmviPRQllgPM1Xsxnn8tcJG727x1WFqGma0nDIi/7O6vnsV1c/aePlzKIRYRmd6z4/Ga/C9rgDio\nvR7oBp52kHaeDnQB1+cHw7GdGnBNfHnxYfdYmtVcvRdTZvYKM7vMzN5mZi80s465667IQc35e/pQ\naUAsIjK9M+Px3inqfxGPZxyhdqR1zcd76CrgQ8DfAt8BHjSzlx1a90Rm7aj5vagBsYjI9PrjcWiK\n+qR86REIi//zAAAgAElEQVRqR1rXXL6Hvgn8KnAi4V8uziIMjJcCXzWzFx5GP0Vm6qj5vahJdSIi\nhyfJwTzcCRlz1Y60rhm/h9z9I3VF9wDvMrNHgE8QJoB+d267JzJrR+z3oiLEIiLTSyIU/VPU99Wd\nN9/tSOs6Eu+hzxCWXDs3TmoSmU9Hze9FDYhFRKZ3TzxOlcN2ejxOlQM31+1I65r395C7jwPJpM+e\nQ21HZIaOmt+LGhCLiEwvWVvz+XF5tFSMoD0DGANuPEg7N8bznlEfeYvtPr/ufiL15uq9OCUzOxNY\nRhgU7zzUdkRmaN7f0zOlAbGIyDTc/X7CkmhrgDfWVV9OiKJ9Mb9GppmdZWaP2bXJ3fcDX4rnb6hr\n502x/e9pDWKZyly9F83sVDNbVd++mR0DfC6+vMrdtVudzAkza4vvxdPy5Yfynp63PmpjDhGR6TXY\nWnQjcAFhzeB7gQvzW4uamQPUb3rQYOvmnwJrgRcD22M798/388jiNRfvRTO7lJArfB1hU4TdwMnA\niwi5nDcBz3P3vfP/RLJYmdlLgJfEl8cDvww8APwolu109z+N564BNgGb3X1NXTuzek/PFw2IRURm\nwMxOAt5H2Fp5OWEHpX8DLnf33XXnNhwQx7oB4L2EPyQrgV2E2fx/6e4Pz+czSHM43PeimT0ReDuw\nDjiBMHFpH3An8DXg7929PP9PIouZmW0g/C6bSjr4nW5AHOtn/J6eLxoQi4iIiEhLUw6xiIiIiLQ0\nDYhFREREpKW11IDYzDx+rVmAe6+P9x480vcWERERkam11IBYRERERKReaaE7cIQlO6JMLmgvRERE\nROSo0VIDYnc/6+BniYiIiEgrUcqEiIiIiLS0RTkgNrMBM3uNmV1tZneb2T4zGzGzu8zsw2Z2whTX\nNZxUZ2YbYvnnzaxgZm8ys5+a2d5Yfm487/Px9QYz6zSzy+P9x8xsu5n9i5mdcQjP02tmLzezL5vZ\nHfG+Y2Z2n5n9g5mdPs216TOZ2clm9o9m9rCZTZjZJjP7GzPrO8j9zzazz8bzx+P9rzez15tZ22yf\nR0RERGQxWawpE+8i7LKTGAa6CFugrgVebWbPdffbZ9muAV8nbKNaJezc00gH8APgaUAZGAeOBV4J\n/JqZvdDdfziL+14KfCL3eh/hw8pp8etVZvYSd/+vado4B/gsMJC7fg3h53SRmV3o7gfkTpvZm4CP\nkX04GgF6gQvj1yvM7BJ3H53F84iIiIgsGosyQgxsAa4AzgOWuHs/YZD6FOB7hMHpV8zsgG1TD+Kl\nhG0D3wD0ufsyYAVhb+68PwKeBLwG6I33fzJwC9ANfM3Mls3ivrsIA+ILgaXu3gd0Egb3XwZ64vP0\nTNPG54GfA0+M1/cCvwtMEH4uv19/gZm9ON53jPAhY4W79xI+XDyfMAlxPfCRWTyLiIiIyKLSdFs3\nm1kHYWD6eGC9u1+Xq0se9hR3H8yVbyDbj/sP3f0fpmj784RBMMCr3f3LdfXHAHcT9uF+j7u/P1e3\nnhBVbriP9zTPY8A1wHOBS939C3X1yTPdCaxz94m6+k8AbwJ+4O7PzpUXgfuB1cBL3f0bDe59CvA/\nhA8bJ7v71pn2W0RERGSxWKwR4inFAeF/xpfPmOXluwhpBwezGfhKg3vvBP4+vnzZLO/dkIdPLN+O\nL6d7ng/XD4ajf4vHs+vK1xMGw4ONBsPx3puAGwmpNetn2GURERGRRWWx5hBjZmcRIp/PIuTK9hJy\ngPMaTq6bxk3uXpnBedf51KH16wjpB2ebWbu7l2dyYzM7EfhjQiT4NGAJB35gme55fjZF+ZZ4rE/h\nuDBp08y2TdNufzyeNM05IiIiIovWohwQm9krgS8CyQoINWCIkC8LYXDcE79mY8cMz9syg7oiYRD6\n6MEaM7OLgG8R+p0YIkzWg5DT28f0zzPVBMCkjfr/1yvjsZ2QJ30w3TM4R0RERGTRWXQpE2Z2LPCP\nhMHwVwkTxjrdfZm7H+/ux5NNApvtpLrqXHRxVieHZc3+mTAY/i9CxLvL3Zfmnudth9L2QST/77/h\n7jaDrw1zeG8RERGRo8ZijBC/kDB4vAt4lbvXGpwzk4jn4ZgudSGJvFaBPTNo6+nAicBu4MVTLG82\nH8+TRK4fPw9ti4iIiCwaiy5CTBg8AtzeaDAcV2V4dn35HLtoBnV3zDB/OHmee6dZ6/e5M+7ZzP0k\nHs80syfMQ/siIiIii8JiHBAPxePZU6wz/PuESWnzaY2Z/WZ9oZkNAH8QX/7rDNtKnud0M+ts0Obz\ngYsPqZfT+3/Ag/H7j8Rl2Bqa5ZrKIiIiIovKYhwQ/xfghGXEPm5mSwHMrM/M/gz4O8LyafNpCPhH\nM3u1mZXi/Z9EtinIduBTM2zremCUsHbxF81sZWyvy8xeB1zNPDxP3LXujwk/y+cB15jZBcmHDDMr\nmdk6M7uCAzcmEREREWkai25A7O73AB+NL98E7DGz3YQc3L8iRD6vnOdufJqwYcWXgP1mNgTcRpjg\nNwq83N1nkj+Mu+8F3hlfvhx4xMz2Eraj/ifgPuDyue1+eu9/J+xmVyakmdwIjJrZTsLqFDcB7wCW\nzsf9RURERI4Gi25ADODubyOkJtxKWGqtRNi2+C3AJcBM1hI+HBOENIb3ETbpaCcs2XYVcJ67/3A2\njbn7xwnbRifR4hJhx7v3EtYLnmpJtcPm7p8DziR8yLiT8LPrJ0SlfwD8KWGdZxEREZGm1HRbN8+n\n3NbNl2sZMhEREZHmsCgjxCIiIiIic0UDYhERERFpaRoQi4iIiEhL04BYRERERFqaJtWJiIiISEtT\nhFhEREREWpoGxCIiIiLS0jQgFhEREZGWpgGxiIiIiLQ0DYhFREREpKWVFroDIiLNyMw2AX3A4AJ3\nRURksVoDDLv7KfN9o6YdELd3rncAt6ysZnGJuVo4WH7JOcudCEB+ObraY0saLVWX3ihrx9MrLP43\nf49YdsB9sybsMQH88H2hWAWgFI8A7aXSYy7ML6WXNF8ohOuLxex/ebUSztu163sNOiEih6mvq6tr\nYO3atQML3RERkcVo48aNjI2NHZF7Ne2AuNjRFb4pZGO9Wt2wb6ajwPq1mhut3ZwMXqdd1dkPHBA3\nXAfa4kDYswFxWxzQdnaE1z1d2em93aGwWDwwAyYZcCf38VwfyuXKdL2VFmVm1wIXufu8flAyszXA\nJuAL7n7pfN5rgQyuXbt24Oabb17ofoiILErr1q3jlltuGTwS91IOsYiIiIi0tKaNEIvIIfsdoHuh\nO9EM7tgyxJrLvr3Q3RARWRCDV1yy0F2YsaYdEBc7wt9zK+WC4Ekebcy5zefvViqTQD6FYer0hnza\nb60aUxEaBNsPyErOpUBkKQwHpky4JTnH2fldHaHPnaWQ5tDbk7W+fGkPAN094VgqZf9bk7Mq1XDd\n2OhEWjcyMn7AvUXc/cGF7oOIiMiRpJQJkRZgZpea2dVm9oCZjZnZsJldb2avbnDutWbmdWXrzczN\nbIOZnW9m3zaz3bFsTTxnMH71m9knzWyLmY2b2V1m9mZrOIO0YV/PMLMrzOwmM9thZhNmttnM/sHM\nTmxwfr5v58a+7TWzUTO7zswunOI+JTN7g5ndGH8eo2Z2q5m9ycz0u1FEpIU0bYS4vStES61UTMuS\nv/CFWJb/i18qtdeV5f92xxUeCuG6/J/1ymSIvNa80XWPjTbng8Feqz8nk6yG0V5qS8uW9oeI9/Il\noQ9Le7Ln6u0M53V2hcl17cnMO6BUDOeVy2UAhvbuT+uKxZED7i1N69PAXcAPga3AcuBFwJfM7Ex3\nf88M23k68E7gx8BngWOAcq6+HfgvYClwVXz9G8DHgDOBN87gHi8FXv//t3fnUZJX9d3H39+qrl6m\nZ6anp2dhFoZhEARBJcIjijwyBgXcHolHg0tcMItKPK6JoJKAWVySKE9CgpgY9UjguIRjjEYfSVQW\nwQWRUZBBlmEEhlm7Z3rvWu/zx/dW/X5TVC8z0z0zXfV5nTPn133v73fvrZ463be//b33Aj8A7ozt\nnwr8AfBKMzszhLCtwXNnAh8EfgR8DlgX+/6emZ0eQvh19UYzywHfBC4Afg3cCEwALwKuAc4C3jSD\nsWJmk62aO3kmz4uIyJHXtBNiEdnPaSGER9IFZtYOfAe43Myum2SSWe984B0hhM9OUr8K2BL7y8d+\nrgTuAi41s6+EEG6bpo/rgaurz6fGe34c7xXAOxs893LgkhDCF1PPvB24DngPcGnq3o/gk+F/BN4b\nQijH+7PAPwNvM7N/DyF8Y5qxiohIE2jaCXF7l+9LVsl2p0qr24xV9xVOornZGPbNxJzjchLyJeBR\n1rZsLv04AJatRoi9sGJP3eaterul2sxUqnnCKdUc41iYa0+iwG1xn7VFfZ0ArOtbXKvrjBHl4fKY\n95f6Y++SJUsAKBR8blEiiR6XQ/KxNLf6yXAsK5jZPwG/DZwHfGkGTW2aYjJc9aH0ZDaEMGBmfwl8\nAbgEj1JPNdaGE/MQws1m9it8ItvIHenJcPR5fNL73GpBTId4F7ADeF91Mhz7KJvZB+I43whMOyEO\nIZzRqDxGjp8z3fMiInLkNe2EWEQSZrYOuAyf+K4DuupuWTPDpn46TX0JT3Ood0u8/tZ0HcRc4zcC\nbwWeDfQC2dQthQaPAfysviCEUDSznbGNqpPwlJGHgCsmSW0eB06ZbqwiItIcNCEWaXJmtgGfyPYC\ntwM3A4NAGT8W8y3ATP9csGOa+j3piGuD53pm0Mengffiuc7fBbbhE1TwSfJxkzy3b5LyEvtPqPvi\n9UTgyinGsXAGYxURkSbQtBPitriortK2qFZm+M/pJFUiiQxlgged+nr9uWI5+Zk+MOg/izMZT5mw\n1PZpZONivFi231HR8bZKdeFcJZVrEfvO7Pdf4A90mKdhtOeSxopFb2NkxK8TqcNgLd43PuFjD6kD\n6NqXe2CsHOcKHam44KLylOfqSfN4Pz4JvKQ+pcDMXo9PiGdqujfNMjPLNpgUHxOvg1M9bGYrgHcD\n9wFnhxCGG4z3UFXH8PUQwqtnoT0REZnnmnZCLCI1T4vXmxrUnTvLfbUBZ+OR6LSN8XrPNM9vwH8z\nvLnBZHhtrD9UD+DR5OeZWS6EUJyFNhs6bU0Pd8+jjelFRFpV006I2zt98Vk5bqcGUAuImkd6M6lg\nV7bsUdauDr9/9dIk5TCbGwBgZMx/bhZSEdhM/EusheqXMr0YL94YF7215ZLIcibj94+OJ4G0Smyr\nFLdALadyG7MxEj1c8evD/ckYivFQkfbg4d+1K5NDxsZz3n7/qF/Hisng86XUC5FmtjVeN+JbjQFg\nZhfgW5nNto+b2XmpXSaW4jtDgC+sm8rWeD0nHWk2s4XAvzAL37NCCCUzuwb4M+AfzOz9IYTx9D1m\ntgroDSHcf6j9iYjI0a9pJ8QiUnMtvmvC18zsJjwn9zTgQuCrwMWz2Nd2PB/5PjP7TyAHvAbfju3a\n6bZcCyHsMLMvA68DNpnZzXje8UvwfYI3AafPwjj/El+w9w58b+Pv41+XFXhu8Qvwrdk0IRYRaQE6\njUmkyYUQfokfOHEnfhjHO4HF+AEY181ydwXgxfjCvdcBb8dzdt+Db3U2E78PfAzfCeOP8W3WvoWn\nYkyZgzxTMU3iIuDN+MEcrwA+gP+SkMGjxzfMRl8iInL0a9oIcYj77mbaO2tllZjWUD2UNpPebSnr\ndSN5Ty3ozSRfmuXLfQVbYaenTkyMJWkOoZp+EVfQGUkaQi520LfUF9Z3diQL3QtFX2BXLA4lZXHN\nXck8LaKUWtjXkYntxhVzo0NJP10LfDH86hX++fHrk36yHf6X4EWxqZH+JNdibO9+KZrSxEIId+L7\nDTdidfdubPD8LfX3TdHXID6RnfJUuhDC1kZthhDG8OjsRxo8dsBjCyGsn6Q84IeAXD/VOEVEpPkp\nQiwiIiIiLa1pI8RnnX4iAHvyyR7+Dz680z/I+fZkbZZ++f5xDBCzcyDZ0rRS9kVrE7GtkPqyhbiI\nLlQjuCRR3TJxsVu7B68WL8jV6vYOjnivmSTSO1H09rPx1LvlC5N+jlsZF/st8sj3ccck27muXO6v\nZ2HO21zet6RWV8Sj23v7HwXg8fGJWt39u3ciIiIi0uoUIRYRERGRlta0EeJXXXAqALlFSWrhf/7X\nvQBsetCjv0Oj+VpdJW7PlomHZ+wbGq3VlcuekxuCH+aV2+9sAo/qVg/fKJHkLBdLXrZ7t+ft9nas\nqNWtXupR3d7uZHwdXR5BPnmVH6S1LPNkrW7lYu+nI+f/ZQtySf5vx4RHf8f6HwdgZPvyWt2uvd7P\nQw9s8msqh3jnhA7iktkzWa6uiIjI0U4RYhERERFpaZoQi4iIiEhLa9qUiZ/fcx8A7/mj5NjUY9d4\nKsFNf/8NAO7aPlKruzcuaMtVPI2gs5ikPpTjPm2ZuAgvU0kW6nW0ezpFOW6Rlp9IFq0t7fYUi5PW\neQrEGSctrdWtWbkYgO6FHbWyJb2LAFiW8e3dnrw3Of12WbfXZXKrAdi5fVut7jf3ezrElq1bAHho\ne5LS8XC/n1rXn/VT7ELv+lpdZuFKRERERFqdIsQiIiIi0tKaNkJ8+y0eIe4b210re/FpawA4u28M\ngNzuZIHZMnwbs1/GxXTDlmyRlo2HYVDyBXeLu9trdSc9bRUA3R6IZeWSZMuzE9d6RHrNMo8293Sl\nDtPo9MhyWy75nSTEfvZufQyA8ZGxWt39T/hY7/z5jwB4ZNuuWt3wsI95qOLjGs4dW6ub6POIcmZR\njE53JHWF8XFEREREWp0ixCIiIiLS0po2QtwWj2z+8V0PJYV3/QSAZzzDo7qnWpLve9xCzx0+6RSP\noN62fUetLjPhOblrl/m2aSdvWF2rO/FEb2thr+cCt5eKtbrxQY9O79zxIAAPjyYR3/F4QMbg4GCt\nbGCv5w6fdux6v254bq3untt87P/9oEeKJzpX1eqWHn8KAB2LPSd4NJ/kJYeY7hyKHn0ulpL/8rYZ\nHcQrIiIi0twUIRYRERGRlqYJsYiIiIi0tKZNmTjpmScBUBlaWyv70UN3ArDz+/cA8Jynr6vVnXK2\nL4A7+5xnet2+p9fqCjFlogvPMRjft71W1/+IL3LbtM1TLLY9+mit7vFtvjXazuEhAEbGktPvxsd8\nQVulXKmVrVh5DAC9F/oWafninlrdWLYXgBf/zjsB+PnD+2p1oxO+mK5Y8OfK48m2cNlqqkTwVX9l\nkoV9uSwi84aZ3QKcG0KYcbKPmQXg1hDCxrkal4iIzH+KEIuIiIhIS2vaCPGxPX7wRWnRolrZ7pFT\nAbhj0Be+bduaRHrP+uEPADijzQ/YOPPsjbW6YptHYB//zRMAjI8kC+4GH/MFc/33++K9HY8lB2Zs\n3xe3cGv3yG3v0jW1utNP3wBAT09PrSzE8zSG8vFQkOHkcJDj1h8HQEePX0eLW2t1mx701zE04v0V\nKgtqdRU64tUjw8mRHVAppz8TaUqnAGPT3iUiIi2taSfEIiIhhAeO9BhEROTop5QJETnizOz/mNn3\nzGy7meXN7Ekzu9XMLm1wb5uZfdjMHor3Pm5mnzSz9gb3hph7nC67KpZvNLO3mNk9ZjZuZrvM7PNm\ndswcvlQRETkKNW2EeG//VgCGR4eTsj1PArCl7Hv5bhtP9gDee58vfNv0qxsBePZd99Xq+k7wVIct\nj+2M1ydqdY/GhXODE56a0LUg2aN41cm+V3B1X+H1xyYpE8es8EV8uVxyIl6x6KkclbKvGerMJv89\nnZ1+X7mS9zZPXFGrW9LjKRlP9I8AsHlr8rr6h7zNTPDFe+n1SJVKsqBP5Egxsz8CPgvsAL4J7AFW\nAM8CLgGurXvkRuB/A98BhoCXAR+Mz1xyAF2/Dzgf+Arw/4Bz4vMbzeysEMLuqR4WEZHm0bQTYhGZ\nN94OFIBnhxB2pSvMbFmD+08ATg0hDMR7PgL8AnizmX0ohLCjwTONvBQ4K4RwT6q/q4H3Ap8Afn8m\njZjZ3ZNUnTzDcYiIyBHWtBPifYO+rdneoSRCvHOXR4Zz1W3K2o6r1f0i52UPxfU3996bLI7r2uzP\n7R33DJOx0F2rswWnA9AeI749fcfW6nKdfl92QXXLsyQavHfQF++Vy8kWaZVqFDfujBZSEdyFC32B\nXecC/y/LpTaeOm6Jj2vNKu+7rT35y/FPfrEVgELJ+66UkyyZgCLEctQoAcX6whDCngb3XladDMd7\nRs3sBuDPgTOBb82wz+vTk+HoKjxK/AYzuzSEkJ9hWyIiMo8ph1hEjrQbgAXAr8zsajO7yMyWT3H/\nzxqUPR6vvQfQ7631BSGEQWAT0InvUDGtEMIZjf4BWtAnIjJPNG2EeMHClQBkF66qlS3JLwGgreLh\n1dCevPyFCzyqumax5+MWRpKdmrbv88BVoej3h2yyHVolNpGv+D2PDSVR4PZhj/6uzHvItz31XM9C\nzznO55MIcbnk92WzfmJGJfX7ykjcIq235M+t6Vtcq8t2+OvpH/dt11Yu6ajVnbrB1wdt2eb5xQOj\nqf4yMz7fQGTOhBA+bWZ7gEuBd+MpC8HMbgX+NITws7r79zVopnrizIEcN7NzkvJqykXPJPUiItJk\nFCEWkSMuhPClEMLzgD7g5cC/Ai8EvmtmK6Z8+OCtnKS8usvE4CT1IiLSZDQhFpGjRghhXwjh2yGE\nPwS+CCzFd5SYC+fWF5hZD3A6MAFsnqN+RUTkKNO0KROjeU95KOaSU9tYEBfDFfyvqh0k62WOievQ\nTujrA2CgI/lraX8+BopKnm5gleSEt1D0v9SW8fSDSib5kpbNF85NFCa822KSotDR6SkPlZC0NTrh\n94W8jyvTnqRYlOJ/VXv8y/C+XGr9UZu3OzDsCwgtJGNY1OGvNZvxfjLZVJpEm34fkiPPzC4E/ieE\n6nLSmmpkeK5OmnuTmf1j3cK6q/BUiS9oQZ2ISOto2gmxiMwbXwYmzOyHwFbA8Kjw/wLuBv5njvr9\nDnCHmX0V2I7vQ3xOHMPlc9SniIgchZp2QhzaPDLatySJEHd1+ssdzHu0tFJItidbscgXw3XF9Wgd\npSR62h6jrIyVY0m5VpcN/nGlFpVNFq3lYhNtWf+gmFpA193ubfZ0L62VjYx5QGqs4NeFlvz3dMTI\nrpmPfbSQBNMKo/7x8IRf86kI9u4BX0w3PO5thmxqzVFG267JUeFy4ALgOfghGxPAb4DLgM+EEJ6y\nHdssuRr4Or6I72JgBE/T+HD9fsgiItLcmnZCLCLzQwjhOuC6Gdy3cYq6L+KT2fryKbdSmew5ERFp\nLU07Ie6MgdDFHUlEtK97EQCrY8Q2Y8nPys42/1LkYyxqZHd/rS4/5od8EKpR42RrtWoT1bzi9E9f\nI+bttvn9hdQaxv5Bj9guSqU4lwseQW6L26F1dyXbp3XmfHxtMVIcQhKlLsYDPErmr3VgLIkej5a9\n72x1y7dKEmzTwRwiIiIi2mVCRERERFqcJsQiIiIi0tKaNmWiPVOO1yQtIBO3LOuMeQ7tueTlW1yE\nNxQX3O0dnqjVTYzH7dbwtINs6jCsTCX2Y95PyCR11a3OigVPUxhLbaM2MOplw6kT8cbGvaxzQcyj\nSG3hVoqpkKEc0yNKSVpEyPniwGq65EQ5WbzXP+hbxlUK1XEmKRMl7SolLSiEcBW+vZqIiAigCLGI\niIiItLimjRC3tfuCtI7OrlpZoRijsqMele3qTBatVbcjG4iL3UaKqUVrWf8yVRfOdVSSCGxftz+3\nbr0f6DGYWtA2sGcIgFxc7GapBe+Fgkd6y6lleMMF//1kqBgP8ghJtLkjFw/YiAv1JvJJpDfb6RHi\niVI80KOcjP30k4/1e8zr1h+/tlb3ozt/goiIiEirU4RYRERERFqaJsQiIiIi0tKaNmViougpCeOp\n1IdSXJA2FBfJFSqp3wcy/vGuPfv8nrEkLaIQsxqycd/eRUmmBWc+Yx0AG05a7M/vTRbjbXnY78+Z\nL6arpmwATJS8/cFUPwNxfV11f+CRwmitrj2mTCzp9vSIzlwy9q4uL1u/YqW/lGR49PX6SXgrVy0E\nYMXyvqTN0ggiIiIirU4RYhERERFpaU0bIR4Z9mhsW/tQrSyT81BvOS5yK5RS9495NHbPPo/wptas\nkY0L39pipHjl0uR4ubUrfdHegpxHdTes6q7V9WQ9Yjs27J/v7k9Ov9tR3XatlGx9Njbh46pUfGDD\n2WRRXVuMCC9b4mXP2NBbq1uzahkAS5f2xueTqPi+fb7tWv82/zoM795ZqzsuPiciIiLSyhQhFhER\nEZGW1rQR4omYOzxRDLWyUIqHWsSiYio6u2ev59NWt1sLqUMxqtulLWz33x+OXdFTq+uKB3+Ecf+8\nuyfZ5s2WeLJxocujusXUgRl78/5A36Lk/mpYOtvmz42nDt8oFjxy3Zn16HRXRxI9XhyTmisVfz0h\nhFSd31+MOdXDw4PJ2LuS+0RERERalSLEIiIiItLSNCEWkaOSmQUzu+UA7t8Yn7mqrvwWM9OfQ0RE\nZFJNmzIxMu7pB5nRZHVcseJpA5WYDjE8kdQNjPjHeb+FSkjSFapfpN4O3z5tcWrbtXLB0xQq5qkP\nlVQaQq4tpjVYZr/+AYpjnjJx4uo1tbJjFnm6xupjV8XXMF6r2/HkLgBW9Hjnyfl2MJH3dIpqpkRH\nR3utrhTTRCw+0N6eDL6cOtFO5r846bs1hLDxSI9FRERkPmnaCbGItJyfAqcAe470QEREZH5p2gnx\neFxEFlIR4kKMllbDq0PjSYQ0X26PVR4Z7ulIsklWLvFDLdYu9ihwW+qvr+Nx0V4pLtCzjuRLGuJW\nadt27gZgy2NP1uq6Y6R27dJFtbKJGCFub/e2lvektnDL9Mbx1ULYtbqhQY8kWwwDT4wn0e183hfy\nVQ8lybUnrysdLRaZ70IIY8ADR3ocIiIy/yiHWOQwMbO3mtlNZrbFzMbNbMjM7jCz32tw71Yz2zpJ\nO8w0FCUAAAyzSURBVFfFXNmNqXarvyGdG+vCJPm0v2tmt5nZYBzDvWb2ITN7ym9H1TGY2UIzu9rM\nHo/PbDKzi+I9bWb2YTN7yMwmzOwRM3vXJOPOmNk7zOwuMxsxs9H48TvNbNLvRWa22syuN7Ndsf+7\nzewNDe5rmEM8FTO7wMy+bWZ7zCwfx/+3ZrZkpm2IiMj817QR4r1Dvo1aR+rwDTI5ACx4tDRfSKKs\n1ezeeEIyizpytboVcVuznm7/mR1SB1+M5/3j4aKfuzxO0mF7t0d4B/b6oR/FQrLt2pq1qwHoSh3B\nXC56pHdo74B/nk8ixPFMEcqx7/HxJIs4X0hykyGJFANMTHibmaz3056KYLdlC8hh9RngfuA2YDvQ\nB7wMuN7Mnh5C+LODbHcT8FHgSuA3wBdTdbdUPzCzjwEfwlMKbgRGgJcCHwMuMLOXhBBSR9IAkAP+\nG1gKfANoB14P3GRm5wOXAmcB3wHywGuBa8xsdwjhK3VtXQ+8AXgc+BwQgN8BrgXOAd7Y4LX1AncC\n+4AvAEuA3wVuMLM1IYS/nfarMwkz+3P86zYAfAvYBTwL+BPgZWb2/BDC0BRNiIhIk2jaCbHIUei0\nEMIj6QIza8cnk5eb2XUhhG0H2mgIYROwycyuBLaGEK6qv8fMno9Phh8HnhtC2BHLPwR8HXgF8Kf4\n5DhtNfBzYGMIIR+fuR6f1H8NeCS+rn2x7tN42sLlQG1CbGavxyfD9wAvDCGMxPIrgFuBN5jZf4UQ\nbqzr/1mxn9eF4L/JmtkngLuBvzazm0IIWw7sKwZm9iJ8Mvwj4GXV8ce6t+KT748C75tBW3dPUnXy\ngY5LRESODKVMiBwm9ZPhWFYA/gn/5fS8Oez+bfH6V9XJcOy/BHwA/yPJH0zy7Hurk+H4zO3Ao3j0\n9rL0ZDJOTu8Anmlm2VQb1f4vr06G4/2jwGXx00b9l2MfldQzjwL/gEev3zTpK57au+P1D9Pjj+1/\nEY+6N4pYi4hIE2raCPHQiKcptJeSdIIQfz5X0xUrqW3QKnHPskrW7xkoJl+aheapBdngZbnUgjYr\ne2rFSMlTJjr2JqmYPT3xRLu4Nduyhan5QfCt0p7clWytlp/wsvGi3z86OlGry8QxT+Srp9GlN16L\n7cZh5XJJukc+v//pddXUCYBsJj1fkblmZuvwyd95wDqgq+6WNU95aPY8J16/X18RQnjQzJ4Ajjez\nJXUTxH2NJvLAk8DxeKS23jb8TXlM/Ljaf4VUCkfKrfjE97ca1D0WJ8D1bsFTRBo9MxPPB4rAa83s\ntQ3q24HlZtYXQuifqqEQwhmNymPk+DmN6kRE5OjStBNikaOJmW3AtwXrBW4HbgYG8YngeuAtwFxu\n+1E9b3z7JPXb8Ul6D56vWzXY+HZPlg8hNKqvJtLnUmU9wECMiO8nhFAysz3AigZt7Zyk/2qUu2eS\n+un04d//rpzmvoXAlBNiERGZ/5p2Qjw66D/T8+NjtbJyLaoa6q7Jh9UIaqkt+Vm+q+wHcuTjH3oz\nqQhxcSIucisX9nseoLt7AQAd7b6lWzaVoTKw2xfOFYrJGqbqYrhSXDhnqbba2vy/qhjvD5UkQlwq\n+XiqUeDUmjoyMQqc1CWV6Qi5zLn345OwS+Kf5Gtifu1b6u6v4FHKRg5mB4TqxPUYPO+33qq6+2bb\nILDUzHL1C/fMrA1YBjRawLZykvaOSbV7sOPJhBCWHuTzIiLSRJRDLHJ4PC1eb2pQd26Dsr3ASjPL\nNag7c5I+KtTyZ57innjdWF9hZk8D1gKP1ufTzqJ78O83L2xQ90J83D9vULfOzNY3KN+Yavdg/Bjo\nNbNTD/J5ERFpIpoQixweW+N1Y7rQzC6g8WKyn+J/wbmk7v63Ai+YpI9+4NhJ6j4fr1eY2fJUe1ng\n7/DvBf862eBnQbX/j5vZglT/C4BPxE8b9Z8FPpnep9jMjscXxZWAfzvI8Vwdr/9iZqvrK82s28ye\nd5Bti4jIPNO0KRNje/30VsumTo6Li+pCbdfhp6YMVBeaFduSQFt5xH8W785WT4lLLcaLWxIXK6XY\ndpJOUV3cVrumzh6opiuk0xYsHqFXjm2E/VIf9v/dpZJK24jZELW0iHSb1eeqqRJtqdcVUhkjMueu\nxSe3XzOzm/DFZqcBFwJfBS6uu/+aeP9nzOw8fLu0ZwNn43vmvqJBH98DXmdm38QXu5WA20IIt4UQ\n7jSzvwE+CNxnZv8OjOL7EJ8G/BA46D19pxNCuNHMXoXvIfwrM/sPPFHpInxx3ldDCDc0ePSX+D7H\nd5vZzXjO8MV42sgHJ1nwN5PxfM/MLgc+DjxkZt/Gd85YCByHR+1/iP//iIhIk2vaCbHI0SSE8Mu4\n9+1f4YdxtAG/AF6NL2K7uO7++83sxfi+wK/EJ7e347sjvJrGE+L34JPM82IfGXwv3dtim5eZ2T3A\nu4A344veHgGuAD7VaMHbLHs9vqPE24C3x7LNwKfwQ0sa2YtP2v8G/wVhMX64yd812LP4gIQQPmlm\nd+DR5nOAV+G5xduAf8YPLzkU6zdv3swZZzTchEJERKaxefNm8IXnc86CwoQiIrPOzPJ4yscvjvRY\npGVVD4d54IiOQlrVbLz/1gNDIYTjD304U1OEWERkbtwHk+9TLDLXqqco6j0oR8J8e/9pUZ2IiIiI\ntDRNiEVERESkpWlCLCIiIiItTRNiEREREWlpmhCLiIiISEvTtmsiIiIi0tIUIRYRERGRlqYJsYiI\niIi0NE2IRURERKSlaUIsIiIiIi1NE2IRERERaWmaEIuIiIhIS9OEWERERERamibEIiIzYGZrzezz\nZvakmeXNbKuZ/V8z6z3AdpbG57bGdp6M7a6dq7FLc5iN96CZ3WJmYYp/nXP5GmT+MrPXmNk1Zna7\nmQ3F98u/HWRbs/L9dDa1HamORUTmCzM7AbgTWAF8A3gAeC7wHuBCM3tBCKF/Bu30xXZOAr4PfBk4\nGbgEeLmZPT+EsGVuXoXMZ7P1Hkz56CTlpUMaqDSzK4BnAyPAE/j3rgM2B+/lWaEJsYjI9K7Fv3m/\nO4RwTbXQzD4NvA/4a+AdM2jnY/hk+OoQwvtT7bwb+PvYz4WzOG5pHrP1HgQghHDVbA9Qmt778Inw\nw8C5wA8Osp1ZfS/PFh3dLCIyBTPbADwCbAVOCCFUUnWLgO2AAStCCKNTtNMN7AYqwKoQwnCqLhP7\nWB/7UJRYambrPRjvvwU4N4RgczZgaXpmthGfEN8QQvi9A3hu1t7Ls005xCIiU/vteL05/c0bIE5q\n7wAWAM+bpp3nA13AHenJcGynAtwcP33RIY9Yms1svQdrzOxiM7vczN5vZi81s47ZG67IpGb9vTxb\nNCEWEZna0+P1wUnqH4rXkw5TO9J65uK982Xg48CngG8Dj5nZaw5ueCIzdtR+H9SEWERkaj3xOjhJ\nfbV8yWFqR1rPbL53vgG8EliL/8XiZHxivAT4ipm99BDGKTKdo/b7oBbViYgcmmou5qEuyJitdqT1\nzPi9E0K4uq7o18CHzexJ4Bp84ed3Znd4IjN2xL4PKkIsIjK1asSiZ5L6xXX3zXU70noOx3vnc/iW\na6fHxU0ic+Go/T6oCbGIyNR+Ha+T5bSdGK+T5cTNdjvSeub8vRNCmACqiz27D7YdkWkctd8HNSEW\nEZlada/N8+P2aDUxkvYCYBz48TTt/Dje94L6CFxs9/y6/kSqZus9OCkzezrQi0+K9xxsOyLTmPP3\n8sHShFhEZAohhEfwLdHWA39cV/1RPJr2pfSemWZ2spntd4pTCGEEuD7ef1VdO++K7X9XexBLvdl6\nD5rZBjNbU9++mS0DvhA//XIIQafVySExs1x8D56QLj+Y9/LhooM5RESm0eCo0c3AWfiewQ8CZ6eP\nGjWzAFB/+EGDo5t/CpwCvArYFdt5ZK5fj8w/s/EeNLO34rnCt+KHIwwA64CX4TmdPwNeEkLYN/ev\nSOYbM7sIuCh+egxwAbAFuD2W7Qkh/Em8dz3wKPCbEML6unYO6L18uGhCLCIyA2Z2LPAX+NHKffiJ\nSv8BfDSEMFB3b8MJcaxbClyJ/2BZBfTjq/r/PITwxFy+BpnfDvU9aGbPBD4AnAGsxhcwDQO/Ar4K\nfDaEUJj7VyLzkZldhX/vmkxt8jvVhDjWz/i9fLhoQiwiIiIiLU05xCIiIiLS0jQhFhEREZGWpgmx\niIiIiLQ0TYhFREREpKVpQiwiIiIiLU0TYhERERFpaZoQi4iIiEhL04RYRERERFqaJsQiIiIi0tI0\nIRYRERGRlqYJsYiIiIi0NE2IRURERKSlaUIsIiIiIi1NE2IRERERaWmaEIuIiIhIS9OEWERERERa\nmibEIiIiItLS/j+9MW+DsAY5XgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b4d27b8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 354
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
